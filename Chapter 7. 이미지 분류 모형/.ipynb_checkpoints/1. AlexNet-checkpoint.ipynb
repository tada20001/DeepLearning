{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지넷에서 주관하는 ILSVRC (Large Scale Visual Recognition Competition) 이라는 대회에서, 2012년 제프리 힌튼 교수팀의 **AlexNet**이 top 5 test error(5개의 예측값 중에 정답이 없는 경우) 기준 15.4%를 기록해 2위(26.2%)를 큰 폭으로 이기고 1위를 차지했다. 이 대회는 1000개의 클래스에 대해, 약 120만장의 이미지를 학습하고 15만장의 이미지를 테스트하여 정답률을 겨루는 대회이다. \n",
    "\n",
    "AlexNet의 등장은 딥러닝, 특히 CNN이 본격적으로 주목 받게 되는 계기가 되었고, 여기서 소개된 ReLU, Dropout 등은 지금도 업계의 표준으로 사용되고 있다.\n",
    "\n",
    "### AlexNet 구조\n",
    "AlexNet의 구조는 5개의 convolution layer, 3개의 fully connected layer로 이루어져 있고, 마지막 레이어의 softmax를 사용하여 예측을 하게 된다."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "유형\t   입력 크기\t      출력 크기\t      커널 크기\t   스트라이드\t활성화함수\n",
    "----------------------------------------------------------------------\n",
    "입력\t   (224,224,3)\t\t\t\t\n",
    "Conv\t(224,224,3)\t    (56,56,96)\t   (11,11)\t     4\t      ReLU\n",
    "Conv\t(56,56,96)\t    (56,56,256)\t   (5,5)\t     1\t      ReLU\n",
    "LRN\t\t\t\t\t\n",
    "maxpool\t(56,56,256) \t(27, 27, 256)\t(3,3)\t     2\t\n",
    "Conv\t(27, 27, 256)\t(27, 27, 384)\t(3,3)\t     1\t      ReLU\n",
    "LRN\t\t\t\t\t\n",
    "maxpool\t(27, 27, 384)\t(13, 13, 384)\t(3,3)\t     2\t\n",
    "Conv\t(13, 13, 384)\t(13, 13, 384)\t(3,3)\t     1\t      ReLcU\n",
    "Conv\t(13, 13, 384)\t(13, 13, 256)\t(3,3)\t     1\t      ReLU\n",
    "maxpool\t(13, 13, 256)\t(6,6,256)\t    (3,3)\t     2\t\n",
    "FCN\t    (9216)\t        (4096)\t\t\t                      ReLu\n",
    "FCN\t    (4096)\t        (4096)\t\t\t                      ReLu\n",
    "FCN\t    (4096)      \t(1000)\t\t\t                      softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlexNet의 특징\n",
    "\n",
    "1. 활성화 함수\n",
    "\n",
    "AlexNet에서는 기존에 사용하던 Sigmoid나 tanh(saturated function; 포화함수) 대신에 ReLU(Rectified Linear Unit)(non-saturated function)을 사용한다. Sigmoid, tanh 함수를 사용했을 때 보다, 학습속도가 6배 가량 빨랐고(논문 주장), exponetial 연산 처럼 연산량이 꽤 드는 작업이 없어 컴퓨터 자원을 많이 절약했으며, Gredient가 더 잘 보존되었다. AlexNet에서는 마지막 Layer를 제외하고는 모두 ReLU를 사용했다.\n",
    "\n",
    "2. GPU를 활용한 병렬 처리\n",
    "\n",
    "AlexNet 저자들이 사용한 GPU모델은 GTX-580 3GB이다. 네트워크를 학습시키기엔 메모리에 한계가 있었기 때문에, 두 대의 GPU를 병렬 처리하여 사용하였다. 이 당시에는 학습을 90 epochs를 수행하는데, 5~6일이 소요되었다고 한다.\n",
    "\n",
    "3. Local Response Normalization\n",
    "\n",
    "활성화 함수로 ReLU를 사용했을 때, 또 하나의 장점은 sigmoid나 tanh 함수에서와 달리, 결과값이 양수에 한해서는 막히지 않았기 때문에, 입력하는 데이터에 대한 정규화 과정이 꼭 필요하지 않다. 하지만, 양수 방향으로 무한히 커질 수 있어 너무 큰 값이 주변 값들을 무시하게 할 수도 있기 때문에, 정규화 과정을 수행하는 것이 generalization 관점에서 좋다.\n",
    "\n",
    "* LRN\n",
    "$$b_{x,y}^i = \\dfrac{a_{x,y}^i}{ \\left (k + \\alpha \\displaystyle\\sum^{min(N-1, i+n/2)}_{j=max(0,i-n/2)}(a_{x,y}^j)^2 \\right )^{\\beta}}$$\n",
    "\n",
    "4. Overlapping Pooling\n",
    "\n",
    "기존의 Pooling 방식은 2x2 kernel size에 strides는 2로 설정하여, 이미지의 크기를 반으로 줄였다. AlexNet에서는 이 대신 3x3 kernel 사이즈에 strides를 2로 설정하여, Pooling kernel이 겹치게 하였다. 이렇게 한 결과, 성능이 top-1 error 는 0.3, top-5 erorr는 0.4 정도 성능 개선이 있었다.\n",
    "\n",
    "\n",
    "5. Data Augmentation\n",
    "\n",
    "AlexNet에서는 과적합 문제를 방지하기 위해서, 아래에서 설명할 Dropout과 함께 Data Augmentation 을 사용했다.\n",
    "\n",
    "5-1. 224x224로 잘라낸 이미지 그리고 원데이터를 좌우반전한 이미지\n",
    "\n",
    "원래 제공되는 이미지는 256x256 이었지만, AlexNet에서는 Data Augmentation을 위해 원데이터와 원데이터를 좌우 반전한 이미지에서 임의로 224x224 이미지를 추출하여 사용했다. 이렇게 해서 1개의 이미지로 2048개의 이미지를 만들어낼 수 있었다. Test 시에는 이미지에서 상하좌우 중앙 의 5개이미지와 이를 반전한 5개 이미지 총 10장에 대한 예측치의 평균을 사용했다.\n",
    "\n",
    "5-2. 학습 이미지로 부터 RGB값을 변화\n",
    "\n",
    "모든 학습 이미지의 픽셀값에 대해 PCA를 수행하고 여기에 평균 0 표준편차 0.1의 정규분포에서 샘플링한 값( 𝛼 )을 곱해주어 원래 픽셀에 더해줌으로써 다양한 이미지를 얻을 수 있었다.\n",
    "\n",
    "$$I_{xy} = [I_{xy}^R, I_{xy}^G, I_{xy}^B] + [v_1, v_2, v_3][\\alpha_1\\lambda_1, \\alpha_2\\lambda_2, \\alpha_2\\lambda_2]^T$$\n",
    "\n",
    "6. Dropout\n",
    "\n",
    "Dropout은 Fully Connected layers 의 앞 두 단계에서 사용되었다. Dropout이 없을 때 보다, 수렴하는 시간은 느리지만 과적합 문제를 극복할 수 있었다고 한다.\n",
    "\n",
    "7. 최적화 과정 : Stochastic Gradient Descent\n",
    "    * batch size = 128\n",
    "    * momentum = 0.9\n",
    "    * weight decay = 0.0005\n",
    "    * learning rate = 0.01 ( 𝜖 )\n",
    "\n",
    "$$v_{i+1} = 0.9v_i - 0.0005 \\epsilon w_i - \\epsilon \\dfrac{\\partial{L}}{\\partial{w_i}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 구현\n",
    "\n",
    "구현함에 앞서, 예제를 만드는 환경은 GPU 하나를 사용하고 있다. 따라서 GPU 병렬화 작업은 포함하지 않았다.\n",
    "\n",
    "그리고, Keras의 Local response normalization(LRN) 명령이 없어졌다. 그래서 아래와 같이 직접 개발하여 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Lambda\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.engine.topology import Layer\n",
    "\n",
    "class LocalResponseNormalization(Layer):\n",
    "    \n",
    "    def __init__(self, n=5, alpha=1e-4, beta=0.75, k=2, **kwargs):\n",
    "        self.n = n\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.k = k\n",
    "        super(LocalResponseNormalization, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.shape = input_shape\n",
    "        super(LocalResponseNormalization, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        _, r, c, f = self.shape\n",
    "        squared = K.square(x)\n",
    "        pooled = K.pool2d(squared, (self.n, self.n), strides=(1, 1), padding='same', pool_mode='avg')\n",
    "        summed = K.sum(pooled, axis=3, keepdims=True)\n",
    "        averaged = self.alpha * K.repeat_elements(summed, f, axis=3)\n",
    "        \n",
    "        denom = K.pow(self.k + averaged, self.beta)\n",
    "        \n",
    "        return x / denom\n",
    "    \n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/imjunghee/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 56, 56, 96)        34944     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 56, 56, 256)       614656    \n",
      "_________________________________________________________________\n",
      "local_response_normalization (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 27, 27, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 27, 27, 384)       885120    \n",
      "_________________________________________________________________\n",
      "local_response_normalization (None, 27, 27, 384)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 13, 13, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 13, 13, 256)       884992    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              37752832  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 62,378,344\n",
      "Trainable params: 62,378,344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(96, (11, 11), strides=4, padding='same', input_shape=input_shape))\n",
    "model.add(Conv2D(256, (5, 5), activation='relu', padding='same'))\n",
    "model.add(LocalResponseNormalization(input_shape=model.output_shape[1:]))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
    "\n",
    "model.add(Conv2D(384, (3, 3), activation='relu', padding='same'))\n",
    "model.add(LocalResponseNormalization(input_shape=model.output_shape[1:]))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
    "\n",
    "model.add(Conv2D(384, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1000, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.SGD(lr=0.01, decay=5e-5, momentum=0.9), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
