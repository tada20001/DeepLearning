{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training에 필요한 세가지 \n",
    "\n",
    "1. Model : hypothesis\n",
    "2. Cost function\n",
    "3. Gradient descent algorithm : 최적화 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariable Linear Regression\n",
    "\n",
    "하나의 input이 아니라 여러 개의 inputs을 넣을 때, 즉 mluti-variable/feature일 때 y_target 값을 예측한다.\n",
    "\n",
    "input이 3개 일때 다음과 같이 선형모형(Model or Hypothesis)을 쓸수 있다.\n",
    "\n",
    "$$ H(x_1, x_2, x_3) = w_1x_1 + w_2x_2 + w_3x_3 + b$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost: 9654.002 \n",
      "Prediction: [64.38505 80.21223 78.03302 80.42699 65.45741]\n",
      "20 Cost: 4.608468 \n",
      "Prediction: [151.5526  184.9665  181.25667 192.83586 145.35411]\n",
      "40 Cost: 4.5926948 \n",
      "Prediction: [151.561   184.9621  181.25974 192.8402  145.34634]\n",
      "60 Cost: 4.5771384 \n",
      "Prediction: [151.56856 184.95676 181.26184 192.8434  145.33786]\n",
      "80 Cost: 4.5616884 \n",
      "Prediction: [151.57608 184.95142 181.26389 192.84662 145.32944]\n",
      "100 Cost: 4.546379 \n",
      "Prediction: [151.58354 184.94612 181.26598 192.84984 145.32104]\n",
      "120 Cost: 4.5311913 \n",
      "Prediction: [151.59096 184.94086 181.268   192.85303 145.31268]\n",
      "140 Cost: 4.5161476 \n",
      "Prediction: [151.59834 184.93561 181.27002 192.8562  145.30437]\n",
      "160 Cost: 4.501248 \n",
      "Prediction: [151.60568 184.93044 181.2721  192.8594  145.29611]\n",
      "180 Cost: 4.4864416 \n",
      "Prediction: [151.61296 184.92525 181.2741  192.86256 145.28786]\n",
      "200 Cost: 4.471822 \n",
      "Prediction: [151.62022 184.92012 181.2761  192.86572 145.2797 ]\n",
      "220 Cost: 4.457287 \n",
      "Prediction: [151.62741 184.91501 181.27808 192.86887 145.27153]\n",
      "240 Cost: 4.442906 \n",
      "Prediction: [151.63457 184.90993 181.28008 192.872   145.26341]\n",
      "260 Cost: 4.4285636 \n",
      "Prediction: [151.64168 184.90486 181.28201 192.87515 145.25533]\n",
      "280 Cost: 4.414461 \n",
      "Prediction: [151.64876 184.89984 181.28395 192.87825 145.24731]\n",
      "300 Cost: 4.400406 \n",
      "Prediction: [151.65579 184.89484 181.28589 192.88135 145.23929]\n",
      "320 Cost: 4.386532 \n",
      "Prediction: [151.6628  184.88988 181.28783 192.88445 145.23135]\n",
      "340 Cost: 4.372716 \n",
      "Prediction: [151.66972 184.88492 181.2897  192.88753 145.22342]\n",
      "360 Cost: 4.3590627 \n",
      "Prediction: [151.67664 184.88002 181.2916  192.89058 145.21553]\n",
      "380 Cost: 4.3454905 \n",
      "Prediction: [151.68353 184.87515 181.29349 192.89369 145.20772]\n",
      "400 Cost: 4.3320565 \n",
      "Prediction: [151.69034 184.87027 181.29536 192.89674 145.1999 ]\n",
      "420 Cost: 4.318738 \n",
      "Prediction: [151.69713 184.86545 181.29724 192.8998  145.19214]\n",
      "440 Cost: 4.305542 \n",
      "Prediction: [151.70387 184.86067 181.29906 192.9028  145.1844 ]\n",
      "460 Cost: 4.292407 \n",
      "Prediction: [151.71057 184.85588 181.3009  192.90585 145.1767 ]\n",
      "480 Cost: 4.2794514 \n",
      "Prediction: [151.71727 184.85115 181.30273 192.90889 145.16908]\n",
      "500 Cost: 4.266577 \n",
      "Prediction: [151.72388 184.84645 181.30457 192.91188 145.16144]\n",
      "520 Cost: 4.253774 \n",
      "Prediction: [151.73047 184.84175 181.30635 192.9149  145.15385]\n",
      "540 Cost: 4.241141 \n",
      "Prediction: [151.73703 184.83708 181.30814 192.91788 145.14632]\n",
      "560 Cost: 4.228546 \n",
      "Prediction: [151.74352 184.83247 181.30992 192.92088 145.1388 ]\n",
      "580 Cost: 4.2161446 \n",
      "Prediction: [151.75003 184.82788 181.31169 192.92386 145.13136]\n",
      "600 Cost: 4.2037444 \n",
      "Prediction: [151.75642 184.82329 181.31342 192.92682 145.12389]\n",
      "620 Cost: 4.1915407 \n",
      "Prediction: [151.76283 184.81874 181.31517 192.92976 145.1165 ]\n",
      "640 Cost: 4.1793885 \n",
      "Prediction: [151.7692  184.81418 181.31688 192.93271 145.10913]\n",
      "660 Cost: 4.167369 \n",
      "Prediction: [151.7755  184.80971 181.3186  192.93562 145.10179]\n",
      "680 Cost: 4.155429 \n",
      "Prediction: [151.7818  184.80524 181.32031 192.93855 145.0945 ]\n",
      "700 Cost: 4.143541 \n",
      "Prediction: [151.78801 184.80077 181.32198 192.94148 145.08722]\n",
      "720 Cost: 4.131845 \n",
      "Prediction: [151.79422 184.79636 181.32367 192.94437 145.08   ]\n",
      "740 Cost: 4.120182 \n",
      "Prediction: [151.80037 184.79196 181.32536 192.94728 145.0728 ]\n",
      "760 Cost: 4.1086283 \n",
      "Prediction: [151.80649 184.7876  181.327   192.95016 145.06564]\n",
      "780 Cost: 4.097195 \n",
      "Prediction: [151.81258 184.78319 181.32861 192.953   145.0585 ]\n",
      "800 Cost: 4.085836 \n",
      "Prediction: [151.81862 184.7789  181.33026 192.95587 145.0514 ]\n",
      "820 Cost: 4.0745378 \n",
      "Prediction: [151.82463 184.7746  181.3319  192.95876 145.04434]\n",
      "840 Cost: 4.063362 \n",
      "Prediction: [151.83064 184.77036 181.33354 192.96164 145.03734]\n",
      "860 Cost: 4.0522847 \n",
      "Prediction: [151.8366  184.76613 181.33514 192.96448 145.03035]\n",
      "880 Cost: 4.0412955 \n",
      "Prediction: [151.8425  184.76189 181.33672 192.9673  145.02339]\n",
      "900 Cost: 4.0304017 \n",
      "Prediction: [151.84837 184.75769 181.33832 192.97014 145.01648]\n",
      "920 Cost: 4.0195336 \n",
      "Prediction: [151.85423 184.75352 181.33989 192.97298 145.00957]\n",
      "940 Cost: 4.0088334 \n",
      "Prediction: [151.86003 184.74936 181.34145 192.97577 145.00272]\n",
      "960 Cost: 3.9981492 \n",
      "Prediction: [151.86578 184.74522 181.34299 192.97859 144.99588]\n",
      "980 Cost: 3.987638 \n",
      "Prediction: [151.87152 184.74115 181.34454 192.98135 144.98909]\n",
      "1000 Cost: 3.9771562 \n",
      "Prediction: [151.87723 184.73706 181.34607 192.98415 144.98233]\n",
      "1020 Cost: 3.9667435 \n",
      "Prediction: [151.88289 184.733   181.34758 192.98694 144.9756 ]\n",
      "1040 Cost: 3.9564285 \n",
      "Prediction: [151.88849 184.72897 181.34906 192.98969 144.96889]\n",
      "1060 Cost: 3.946183 \n",
      "Prediction: [151.89409 184.72499 181.35057 192.99246 144.96222]\n",
      "1080 Cost: 3.9360378 \n",
      "Prediction: [151.89966 184.72098 181.35208 192.99521 144.95557]\n",
      "1100 Cost: 3.925979 \n",
      "Prediction: [151.9052  184.71706 181.35356 192.99797 144.94899]\n",
      "1120 Cost: 3.9159896 \n",
      "Prediction: [151.91069 184.71312 181.35506 193.00072 144.94241]\n",
      "1140 Cost: 3.9061007 \n",
      "Prediction: [151.91617 184.70923 181.3565  193.00343 144.93588]\n",
      "1160 Cost: 3.8962402 \n",
      "Prediction: [151.92157 184.7053  181.35793 193.00615 144.92935]\n",
      "1180 Cost: 3.8864975 \n",
      "Prediction: [151.92694 184.70142 181.35933 193.00882 144.92285]\n",
      "1200 Cost: 3.8768203 \n",
      "Prediction: [151.93231 184.69757 181.36076 193.01154 144.91641]\n",
      "1220 Cost: 3.8672123 \n",
      "Prediction: [151.93765 184.69379 181.36217 193.01422 144.90999]\n",
      "1240 Cost: 3.8576977 \n",
      "Prediction: [151.94295 184.68997 181.3636  193.01692 144.90361]\n",
      "1260 Cost: 3.84821 \n",
      "Prediction: [151.94823 184.68623 181.36504 193.01964 144.89725]\n",
      "1280 Cost: 3.8388093 \n",
      "Prediction: [151.95345 184.6825  181.3664  193.02231 144.89091]\n",
      "1300 Cost: 3.8295074 \n",
      "Prediction: [151.95862 184.6787  181.36775 193.02492 144.88457]\n",
      "1320 Cost: 3.8203003 \n",
      "Prediction: [151.96378 184.67497 181.36914 193.02756 144.8783 ]\n",
      "1340 Cost: 3.811109 \n",
      "Prediction: [151.96895 184.67133 181.37048 193.03026 144.8721 ]\n",
      "1360 Cost: 3.8019996 \n",
      "Prediction: [151.97404 184.66768 181.37184 193.03288 144.86586]\n",
      "1380 Cost: 3.792981 \n",
      "Prediction: [151.97913 184.664   181.3732  193.03552 144.85968]\n",
      "1400 Cost: 3.7839985 \n",
      "Prediction: [151.98416 184.66039 181.37451 193.03816 144.85353]\n",
      "1420 Cost: 3.7750983 \n",
      "Prediction: [151.98917 184.65675 181.37581 193.04076 144.84738]\n",
      "1440 Cost: 3.7662888 \n",
      "Prediction: [151.99414 184.6532  181.37714 193.04337 144.8413 ]\n",
      "1460 Cost: 3.7575455 \n",
      "Prediction: [151.9991  184.64966 181.37846 193.04597 144.83524]\n",
      "1480 Cost: 3.7488232 \n",
      "Prediction: [152.00401 184.64609 181.37973 193.04858 144.8292 ]\n",
      "1500 Cost: 3.740207 \n",
      "Prediction: [152.0089  184.64256 181.38101 193.05113 144.82315]\n",
      "1520 Cost: 3.7316184 \n",
      "Prediction: [152.01375 184.63905 181.3823  193.05373 144.81715]\n",
      "1540 Cost: 3.7231205 \n",
      "Prediction: [152.01859 184.63562 181.38354 193.0563  144.81122]\n",
      "1560 Cost: 3.7146668 \n",
      "Prediction: [152.02339 184.63216 181.38481 193.05888 144.80528]\n",
      "1580 Cost: 3.7062924 \n",
      "Prediction: [152.02814 184.62872 181.38605 193.06143 144.79938]\n",
      "1600 Cost: 3.6979797 \n",
      "Prediction: [152.03285 184.62526 181.38727 193.06396 144.79349]\n",
      "1620 Cost: 3.68974 \n",
      "Prediction: [152.03758 184.6219  181.38853 193.06651 144.78764]\n",
      "1640 Cost: 3.681533 \n",
      "Prediction: [152.0423  184.61853 181.38974 193.06906 144.78183]\n",
      "1660 Cost: 3.673371 \n",
      "Prediction: [152.04692 184.61516 181.39098 193.07161 144.77602]\n",
      "1680 Cost: 3.6653557 \n",
      "Prediction: [152.05156 184.61183 181.39215 193.07408 144.77026]\n",
      "1700 Cost: 3.6573226 \n",
      "Prediction: [152.05614 184.6085  181.39334 193.0766  144.76451]\n",
      "1720 Cost: 3.6493332 \n",
      "Prediction: [152.0607  184.60524 181.39452 193.07913 144.7588 ]\n",
      "1740 Cost: 3.6414196 \n",
      "Prediction: [152.06523 184.60194 181.3957  193.08165 144.75311]\n",
      "1760 Cost: 3.633554 \n",
      "Prediction: [152.06976 184.5987  181.39685 193.08414 144.74744]\n",
      "1780 Cost: 3.6258197 \n",
      "Prediction: [152.07422 184.59543 181.39803 193.0866  144.7418 ]\n",
      "1800 Cost: 3.6180756 \n",
      "Prediction: [152.07869 184.59222 181.39919 193.0891  144.7362 ]\n",
      "1820 Cost: 3.6104126 \n",
      "Prediction: [152.08313 184.58905 181.40036 193.09158 144.73064]\n",
      "1840 Cost: 3.602803 \n",
      "Prediction: [152.08748 184.58583 181.40144 193.09398 144.72504]\n",
      "1860 Cost: 3.5952206 \n",
      "Prediction: [152.0919  184.58269 181.40259 193.09648 144.71953]\n",
      "1880 Cost: 3.587703 \n",
      "Prediction: [152.09622 184.57956 181.40372 193.09894 144.71402]\n",
      "1900 Cost: 3.5802426 \n",
      "Prediction: [152.10051 184.5764  181.40483 193.10136 144.70851]\n",
      "1920 Cost: 3.5728118 \n",
      "Prediction: [152.10481 184.5733  181.40591 193.10382 144.70306]\n",
      "1940 Cost: 3.5654347 \n",
      "Prediction: [152.1091  184.57028 181.40704 193.1063  144.69765]\n",
      "1960 Cost: 3.5581412 \n",
      "Prediction: [152.11333 184.56717 181.4081  193.10869 144.69223]\n",
      "1980 Cost: 3.550901 \n",
      "Prediction: [152.11752 184.56409 181.40915 193.11107 144.68683]\n",
      "2000 Cost: 3.543682 \n",
      "Prediction: [152.12173 184.5611  181.41026 193.11353 144.68149]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "x1_data = [73, 93, 89, 96, 73]\n",
    "x2_data = [80, 88, 91, 98, 66]\n",
    "x3_data = [75, 93, 90, 100, 70]\n",
    "y_data = [152, 185, 180, 196, 142]\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "x1 = tf.placeholder(tf.float32)\n",
    "x2 = tf.placeholder(tf.float32)\n",
    "x3 = tf.placeholder(tf.float32)\n",
    "\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "# Variables\n",
    "w1 = tf.Variable(tf.random_normal([1]), name='weight1')\n",
    "w2 = tf.Variable(tf.random_normal([1]), name='weight2')\n",
    "w3 = tf.Variable(tf.random_normal([1]), name='weight3')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# model\n",
    "hypothesis = x1 * w1 + x2 * w2 + x3 * w3 + b\n",
    "\n",
    "# cost function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# minimize \n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train], feed_dict={x1: x1_data, x2: x2_data, x3: x3_data, Y: y_data})\n",
    "    \n",
    "    if step % 20 == 0:\n",
    "        print(step, \"Cost:\", cost_val, \"\\nPrediction:\", hy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[152, 185, 180, 196, 142]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측 결과, 실제 y_data 값과 거의 유사한 값으로 수렴되었다.\n",
    "\n",
    "### matrix를 이용해 다시 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost: 245451.55 \n",
      "Prediction: [[-289.36374]\n",
      " [-342.9916 ]\n",
      " [-340.4735 ]\n",
      " [-369.8221 ]\n",
      " [-261.2781 ]]\n",
      "20 Cost: 0.9109496 \n",
      "Prediction: [[150.23128]\n",
      " [185.36198]\n",
      " [180.12592]\n",
      " [197.09642]\n",
      " [141.7219 ]]\n",
      "40 Cost: 0.90845174 \n",
      "Prediction: [[150.2389 ]\n",
      " [185.36438]\n",
      " [180.13188]\n",
      " [197.10178]\n",
      " [141.72299]]\n",
      "60 Cost: 0.90596163 \n",
      "Prediction: [[150.24254]\n",
      " [185.36197]\n",
      " [180.13307]\n",
      " [197.10193]\n",
      " [141.72043]]\n",
      "80 Cost: 0.90351087 \n",
      "Prediction: [[150.24614]\n",
      " [185.35957]\n",
      " [180.13426]\n",
      " [197.1021 ]\n",
      " [141.71788]]\n",
      "100 Cost: 0.9010662 \n",
      "Prediction: [[150.24973]\n",
      " [185.35718]\n",
      " [180.13545]\n",
      " [197.10223]\n",
      " [141.71535]]\n",
      "120 Cost: 0.8986536 \n",
      "Prediction: [[150.2533 ]\n",
      " [185.35483]\n",
      " [180.13663]\n",
      " [197.10239]\n",
      " [141.71283]]\n",
      "140 Cost: 0.89626056 \n",
      "Prediction: [[150.25684]\n",
      " [185.35245]\n",
      " [180.13782]\n",
      " [197.10252]\n",
      " [141.71033]]\n",
      "160 Cost: 0.8938885 \n",
      "Prediction: [[150.26038]\n",
      " [185.35011]\n",
      " [180.13899]\n",
      " [197.10268]\n",
      " [141.70784]]\n",
      "180 Cost: 0.8915469 \n",
      "Prediction: [[150.26387]\n",
      " [185.34776]\n",
      " [180.14015]\n",
      " [197.10281]\n",
      " [141.70537]]\n",
      "200 Cost: 0.8892072 \n",
      "Prediction: [[150.26738]\n",
      " [185.34544]\n",
      " [180.14131]\n",
      " [197.10295]\n",
      " [141.70291]]\n",
      "220 Cost: 0.8868866 \n",
      "Prediction: [[150.27087]\n",
      " [185.34314]\n",
      " [180.14247]\n",
      " [197.10309]\n",
      " [141.70049]]\n",
      "240 Cost: 0.88459855 \n",
      "Prediction: [[150.27432]\n",
      " [185.34082]\n",
      " [180.14363]\n",
      " [197.10321]\n",
      " [141.69806]]\n",
      "260 Cost: 0.8823274 \n",
      "Prediction: [[150.27776]\n",
      " [185.33853]\n",
      " [180.14478]\n",
      " [197.10332]\n",
      " [141.69563]]\n",
      "280 Cost: 0.88007414 \n",
      "Prediction: [[150.2812 ]\n",
      " [185.33627]\n",
      " [180.14592]\n",
      " [197.10347]\n",
      " [141.69325]]\n",
      "300 Cost: 0.8778405 \n",
      "Prediction: [[150.28459]\n",
      " [185.33398]\n",
      " [180.14705]\n",
      " [197.10356]\n",
      " [141.69087]]\n",
      "320 Cost: 0.8756358 \n",
      "Prediction: [[150.28798]\n",
      " [185.33174]\n",
      " [180.14818]\n",
      " [197.10368]\n",
      " [141.68849]]\n",
      "340 Cost: 0.8734339 \n",
      "Prediction: [[150.29137]\n",
      " [185.3295 ]\n",
      " [180.14929]\n",
      " [197.1038 ]\n",
      " [141.68616]]\n",
      "360 Cost: 0.87124765 \n",
      "Prediction: [[150.29474]\n",
      " [185.32727]\n",
      " [180.15042]\n",
      " [197.10391]\n",
      " [141.68382]]\n",
      "380 Cost: 0.8690945 \n",
      "Prediction: [[150.29807]\n",
      " [185.32504]\n",
      " [180.15154]\n",
      " [197.104  ]\n",
      " [141.68149]]\n",
      "400 Cost: 0.8669454 \n",
      "Prediction: [[150.30139]\n",
      " [185.32281]\n",
      " [180.15263]\n",
      " [197.1041 ]\n",
      " [141.67918]]\n",
      "420 Cost: 0.8648178 \n",
      "Prediction: [[150.30472]\n",
      " [185.32063]\n",
      " [180.15376]\n",
      " [197.1042 ]\n",
      " [141.6769 ]]\n",
      "440 Cost: 0.8627167 \n",
      "Prediction: [[150.308  ]\n",
      " [185.31844]\n",
      " [180.15485]\n",
      " [197.1043 ]\n",
      " [141.67462]]\n",
      "460 Cost: 0.86062896 \n",
      "Prediction: [[150.31128]\n",
      " [185.31627]\n",
      " [180.15594]\n",
      " [197.10439]\n",
      " [141.67235]]\n",
      "480 Cost: 0.8585585 \n",
      "Prediction: [[150.31454]\n",
      " [185.31412]\n",
      " [180.15704]\n",
      " [197.10448]\n",
      " [141.6701 ]]\n",
      "500 Cost: 0.8565043 \n",
      "Prediction: [[150.31778]\n",
      " [185.31195]\n",
      " [180.15811]\n",
      " [197.10455]\n",
      " [141.66788]]\n",
      "520 Cost: 0.8544693 \n",
      "Prediction: [[150.32101]\n",
      " [185.3098 ]\n",
      " [180.15921]\n",
      " [197.10464]\n",
      " [141.66565]]\n",
      "540 Cost: 0.8524405 \n",
      "Prediction: [[150.32425]\n",
      " [185.30768]\n",
      " [180.16028]\n",
      " [197.10474]\n",
      " [141.66345]]\n",
      "560 Cost: 0.85044396 \n",
      "Prediction: [[150.32744]\n",
      " [185.30556]\n",
      " [180.16135]\n",
      " [197.10481]\n",
      " [141.66125]]\n",
      "580 Cost: 0.8484578 \n",
      "Prediction: [[150.33061]\n",
      " [185.30345]\n",
      " [180.1624 ]\n",
      " [197.10487]\n",
      " [141.65907]]\n",
      "600 Cost: 0.84647876 \n",
      "Prediction: [[150.33379]\n",
      " [185.30135]\n",
      " [180.16347]\n",
      " [197.10493]\n",
      " [141.6569 ]]\n",
      "620 Cost: 0.84452355 \n",
      "Prediction: [[150.33694]\n",
      " [185.29926]\n",
      " [180.16452]\n",
      " [197.10501]\n",
      " [141.65475]]\n",
      "640 Cost: 0.84257257 \n",
      "Prediction: [[150.34009]\n",
      " [185.29718]\n",
      " [180.16557]\n",
      " [197.10506]\n",
      " [141.65262]]\n",
      "660 Cost: 0.84065664 \n",
      "Prediction: [[150.3432 ]\n",
      " [185.2951 ]\n",
      " [180.16663]\n",
      " [197.10512]\n",
      " [141.65048]]\n",
      "680 Cost: 0.83876437 \n",
      "Prediction: [[150.3463 ]\n",
      " [185.29308]\n",
      " [180.16768]\n",
      " [197.1052 ]\n",
      " [141.64839]]\n",
      "700 Cost: 0.83686316 \n",
      "Prediction: [[150.34938]\n",
      " [185.291  ]\n",
      " [180.16869]\n",
      " [197.10522]\n",
      " [141.64629]]\n",
      "720 Cost: 0.8349821 \n",
      "Prediction: [[150.35246]\n",
      " [185.28896]\n",
      " [180.16972]\n",
      " [197.10527]\n",
      " [141.64418]]\n",
      "740 Cost: 0.8331288 \n",
      "Prediction: [[150.35553]\n",
      " [185.28696]\n",
      " [180.17076]\n",
      " [197.10535]\n",
      " [141.64214]]\n",
      "760 Cost: 0.83126867 \n",
      "Prediction: [[150.35858]\n",
      " [185.28491]\n",
      " [180.17178]\n",
      " [197.10538]\n",
      " [141.64008]]\n",
      "780 Cost: 0.82944024 \n",
      "Prediction: [[150.3616 ]\n",
      " [185.28291]\n",
      " [180.17279]\n",
      " [197.10541]\n",
      " [141.63802]]\n",
      "800 Cost: 0.82762444 \n",
      "Prediction: [[150.36461]\n",
      " [185.28091]\n",
      " [180.1738 ]\n",
      " [197.10544]\n",
      " [141.63599]]\n",
      "820 Cost: 0.8258235 \n",
      "Prediction: [[150.36761]\n",
      " [185.27893]\n",
      " [180.17482]\n",
      " [197.10548]\n",
      " [141.63397]]\n",
      "840 Cost: 0.82404006 \n",
      "Prediction: [[150.37059]\n",
      " [185.27693]\n",
      " [180.1758 ]\n",
      " [197.10551]\n",
      " [141.63194]]\n",
      "860 Cost: 0.82225436 \n",
      "Prediction: [[150.37358]\n",
      " [185.27498]\n",
      " [180.1768 ]\n",
      " [197.10555]\n",
      " [141.62996]]\n",
      "880 Cost: 0.82049817 \n",
      "Prediction: [[150.37653]\n",
      " [185.27304]\n",
      " [180.17781]\n",
      " [197.10556]\n",
      " [141.62799]]\n",
      "900 Cost: 0.81875503 \n",
      "Prediction: [[150.37947]\n",
      " [185.27109]\n",
      " [180.1788 ]\n",
      " [197.10559]\n",
      " [141.626  ]]\n",
      "920 Cost: 0.8170196 \n",
      "Prediction: [[150.38239]\n",
      " [185.26913]\n",
      " [180.17978]\n",
      " [197.10559]\n",
      " [141.62405]]\n",
      "940 Cost: 0.81529284 \n",
      "Prediction: [[150.38533]\n",
      " [185.26723]\n",
      " [180.18077]\n",
      " [197.10564]\n",
      " [141.62213]]\n",
      "960 Cost: 0.8135942 \n",
      "Prediction: [[150.3882 ]\n",
      " [185.26529]\n",
      " [180.18173]\n",
      " [197.10562]\n",
      " [141.62018]]\n",
      "980 Cost: 0.8119014 \n",
      "Prediction: [[150.3911 ]\n",
      " [185.26338]\n",
      " [180.18272]\n",
      " [197.10565]\n",
      " [141.61827]]\n",
      "1000 Cost: 0.8102298 \n",
      "Prediction: [[150.39397]\n",
      " [185.26149]\n",
      " [180.18369]\n",
      " [197.10567]\n",
      " [141.61635]]\n",
      "1020 Cost: 0.80856055 \n",
      "Prediction: [[150.39682]\n",
      " [185.2596 ]\n",
      " [180.18465]\n",
      " [197.10567]\n",
      " [141.61447]]\n",
      "1040 Cost: 0.80691177 \n",
      "Prediction: [[150.39966]\n",
      " [185.25772]\n",
      " [180.18561]\n",
      " [197.10567]\n",
      " [141.61258]]\n",
      "1060 Cost: 0.80526495 \n",
      "Prediction: [[150.4025 ]\n",
      " [185.25586]\n",
      " [180.18655]\n",
      " [197.10567]\n",
      " [141.61072]]\n",
      "1080 Cost: 0.8036436 \n",
      "Prediction: [[150.40532]\n",
      " [185.25401]\n",
      " [180.18755]\n",
      " [197.10568]\n",
      " [141.60887]]\n",
      "1100 Cost: 0.8020116 \n",
      "Prediction: [[150.40813]\n",
      " [185.25214]\n",
      " [180.18846]\n",
      " [197.10565]\n",
      " [141.60701]]\n",
      "1120 Cost: 0.80042076 \n",
      "Prediction: [[150.4109 ]\n",
      " [185.2503 ]\n",
      " [180.1894 ]\n",
      " [197.10565]\n",
      " [141.60518]]\n",
      "1140 Cost: 0.79882294 \n",
      "Prediction: [[150.4137 ]\n",
      " [185.24847]\n",
      " [180.19034]\n",
      " [197.10565]\n",
      " [141.60336]]\n",
      "1160 Cost: 0.79725015 \n",
      "Prediction: [[150.41644]\n",
      " [185.24664]\n",
      " [180.19128]\n",
      " [197.10562]\n",
      " [141.60153]]\n",
      "1180 Cost: 0.7956845 \n",
      "Prediction: [[150.41919]\n",
      " [185.24483]\n",
      " [180.1922 ]\n",
      " [197.1056 ]\n",
      " [141.59973]]\n",
      "1200 Cost: 0.7941264 \n",
      "Prediction: [[150.42195]\n",
      " [185.24303]\n",
      " [180.19316]\n",
      " [197.10562]\n",
      " [141.59798]]\n",
      "1220 Cost: 0.79258 \n",
      "Prediction: [[150.42467]\n",
      " [185.24123]\n",
      " [180.19408]\n",
      " [197.10558]\n",
      " [141.59618]]\n",
      "1240 Cost: 0.7910632 \n",
      "Prediction: [[150.42735]\n",
      " [185.23946]\n",
      " [180.19499]\n",
      " [197.10555]\n",
      " [141.5944 ]]\n",
      "1260 Cost: 0.7895432 \n",
      "Prediction: [[150.43004]\n",
      " [185.23766]\n",
      " [180.19589]\n",
      " [197.10551]\n",
      " [141.59267]]\n",
      "1280 Cost: 0.7880316 \n",
      "Prediction: [[150.43274]\n",
      " [185.2359 ]\n",
      " [180.19681]\n",
      " [197.1055 ]\n",
      " [141.59093]]\n",
      "1300 Cost: 0.7865449 \n",
      "Prediction: [[150.4354 ]\n",
      " [185.23413]\n",
      " [180.19771]\n",
      " [197.10547]\n",
      " [141.58919]]\n",
      "1320 Cost: 0.7850536 \n",
      "Prediction: [[150.43805]\n",
      " [185.23238]\n",
      " [180.19861]\n",
      " [197.10542]\n",
      " [141.58748]]\n",
      "1340 Cost: 0.78356636 \n",
      "Prediction: [[150.44072]\n",
      " [185.23064]\n",
      " [180.19951]\n",
      " [197.1054 ]\n",
      " [141.58577]]\n",
      "1360 Cost: 0.7821132 \n",
      "Prediction: [[150.44334]\n",
      " [185.2289 ]\n",
      " [180.20041]\n",
      " [197.10536]\n",
      " [141.58406]]\n",
      "1380 Cost: 0.7806565 \n",
      "Prediction: [[150.44595]\n",
      " [185.22717]\n",
      " [180.2013 ]\n",
      " [197.1053 ]\n",
      " [141.58238]]\n",
      "1400 Cost: 0.77921724 \n",
      "Prediction: [[150.44858]\n",
      " [185.22546]\n",
      " [180.20221]\n",
      " [197.10529]\n",
      " [141.58072]]\n",
      "1420 Cost: 0.77779055 \n",
      "Prediction: [[150.45114]\n",
      " [185.22375]\n",
      " [180.20305]\n",
      " [197.10521]\n",
      " [141.57904]]\n",
      "1440 Cost: 0.77636355 \n",
      "Prediction: [[150.45374]\n",
      " [185.22205]\n",
      " [180.20395]\n",
      " [197.10516]\n",
      " [141.5774 ]]\n",
      "1460 Cost: 0.7749675 \n",
      "Prediction: [[150.4563 ]\n",
      " [185.22037]\n",
      " [180.20482]\n",
      " [197.10513]\n",
      " [141.57574]]\n",
      "1480 Cost: 0.77355665 \n",
      "Prediction: [[150.45886]\n",
      " [185.21867]\n",
      " [180.20569]\n",
      " [197.10507]\n",
      " [141.57413]]\n",
      "1500 Cost: 0.77215743 \n",
      "Prediction: [[150.46141]\n",
      " [185.217  ]\n",
      " [180.20656]\n",
      " [197.105  ]\n",
      " [141.5725 ]]\n",
      "1520 Cost: 0.77078104 \n",
      "Prediction: [[150.46394]\n",
      " [185.21533]\n",
      " [180.20741]\n",
      " [197.10495]\n",
      " [141.57089]]\n",
      "1540 Cost: 0.7694122 \n",
      "Prediction: [[150.46646]\n",
      " [185.21368]\n",
      " [180.20828]\n",
      " [197.10489]\n",
      " [141.5693 ]]\n",
      "1560 Cost: 0.7680591 \n",
      "Prediction: [[150.46896]\n",
      " [185.21204]\n",
      " [180.20914]\n",
      " [197.10483]\n",
      " [141.5677 ]]\n",
      "1580 Cost: 0.76670414 \n",
      "Prediction: [[150.47147]\n",
      " [185.21039]\n",
      " [180.20998]\n",
      " [197.10477]\n",
      " [141.56613]]\n",
      "1600 Cost: 0.7653606 \n",
      "Prediction: [[150.47395]\n",
      " [185.20876]\n",
      " [180.21085]\n",
      " [197.10469]\n",
      " [141.56456]]\n",
      "1620 Cost: 0.7640339 \n",
      "Prediction: [[150.47641]\n",
      " [185.2071 ]\n",
      " [180.21169]\n",
      " [197.10461]\n",
      " [141.563  ]]\n",
      "1640 Cost: 0.76271576 \n",
      "Prediction: [[150.47887]\n",
      " [185.2055 ]\n",
      " [180.21252]\n",
      " [197.10454]\n",
      " [141.56145]]\n",
      "1660 Cost: 0.76140106 \n",
      "Prediction: [[150.48134]\n",
      " [185.20392]\n",
      " [180.21338]\n",
      " [197.10449]\n",
      " [141.55994]]\n",
      "1680 Cost: 0.7600988 \n",
      "Prediction: [[150.48376]\n",
      " [185.2023 ]\n",
      " [180.2142 ]\n",
      " [197.1044 ]\n",
      " [141.5584 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700 Cost: 0.7587969 \n",
      "Prediction: [[150.48619]\n",
      " [185.2007 ]\n",
      " [180.21503]\n",
      " [197.10431]\n",
      " [141.55688]]\n",
      "1720 Cost: 0.75751686 \n",
      "Prediction: [[150.4886 ]\n",
      " [185.19911]\n",
      " [180.21585]\n",
      " [197.10423]\n",
      " [141.55537]]\n",
      "1740 Cost: 0.7562331 \n",
      "Prediction: [[150.49101]\n",
      " [185.19754]\n",
      " [180.21667]\n",
      " [197.10414]\n",
      " [141.55388]]\n",
      "1760 Cost: 0.7549708 \n",
      "Prediction: [[150.4934 ]\n",
      " [185.19597]\n",
      " [180.21748]\n",
      " [197.10405]\n",
      " [141.55238]]\n",
      "1780 Cost: 0.7537116 \n",
      "Prediction: [[150.49577]\n",
      " [185.1944 ]\n",
      " [180.2183 ]\n",
      " [197.10396]\n",
      " [141.5509 ]]\n",
      "1800 Cost: 0.7524697 \n",
      "Prediction: [[150.49814]\n",
      " [185.19284]\n",
      " [180.21912]\n",
      " [197.10388]\n",
      " [141.54944]]\n",
      "1820 Cost: 0.75123274 \n",
      "Prediction: [[150.50049]\n",
      " [185.19131]\n",
      " [180.21994]\n",
      " [197.10379]\n",
      " [141.548  ]]\n",
      "1840 Cost: 0.7499938 \n",
      "Prediction: [[150.50284]\n",
      " [185.18976]\n",
      " [180.22073]\n",
      " [197.10368]\n",
      " [141.54654]]\n",
      "1860 Cost: 0.74878496 \n",
      "Prediction: [[150.50517]\n",
      " [185.18825]\n",
      " [180.22154]\n",
      " [197.10362]\n",
      " [141.54512]]\n",
      "1880 Cost: 0.7475549 \n",
      "Prediction: [[150.50749]\n",
      " [185.1867 ]\n",
      " [180.22234]\n",
      " [197.10349]\n",
      " [141.54369]]\n",
      "1900 Cost: 0.7463419 \n",
      "Prediction: [[150.50981]\n",
      " [185.1852 ]\n",
      " [180.22313]\n",
      " [197.10338]\n",
      " [141.54227]]\n",
      "1920 Cost: 0.7451463 \n",
      "Prediction: [[150.51213]\n",
      " [185.1837 ]\n",
      " [180.22394]\n",
      " [197.1033 ]\n",
      " [141.54086]]\n",
      "1940 Cost: 0.74395645 \n",
      "Prediction: [[150.5144 ]\n",
      " [185.18219]\n",
      " [180.2247 ]\n",
      " [197.10318]\n",
      " [141.53946]]\n",
      "1960 Cost: 0.7427745 \n",
      "Prediction: [[150.51668]\n",
      " [185.1807 ]\n",
      " [180.2255 ]\n",
      " [197.10306]\n",
      " [141.53806]]\n",
      "1980 Cost: 0.7416043 \n",
      "Prediction: [[150.51895]\n",
      " [185.1792 ]\n",
      " [180.22629]\n",
      " [197.10297]\n",
      " [141.53668]]\n",
      "2000 Cost: 0.7404384 \n",
      "Prediction: [[150.52121]\n",
      " [185.17773]\n",
      " [180.22707]\n",
      " [197.10286]\n",
      " [141.53532]]\n"
     ]
    }
   ],
   "source": [
    "x1_data = [73, 93, 89, 96, 73]\n",
    "x2_data = [80, 88, 91, 98, 66]\n",
    "x3_data = [75, 93, 90, 100, 70]\n",
    "\n",
    "x_data = [[73., 80., 75.], [93., 88., 93.], [89., 91., 90], [96., 98., 100.], [73., 66., 70]]\n",
    "y_data = [[152.], [185.], [180.], [196.], [142.]]\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])  # 여기에서는 None=5 데이터 수\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# model\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# cost function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize and train\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "    \n",
    "    if step % 20 == 0:\n",
    "        print(step, \"Cost:\", cost_val, \"\\nPrediction:\", hy_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제 값 : y_data = [[152.], [185.], [180.], [196.], [142.]]\n",
    "\n",
    "cost 값 0.74로 수렴하고 예측값도 거의 실제값과 유사하게 수렴된다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data from file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%writefile 매칭 명령으로 csv 파일 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sample1.csv\n"
     ]
    }
   ],
   "source": [
    "%%writefile sample1.csv\n",
    "#EXAM1, EXAM2, EXAM3, FINAL\n",
    "73, 80, 75, 152\n",
    "93, 88, 93, 185\n",
    "89, 91, 90, 180\n",
    "96, 98, 100, 196\n",
    "73, 66, 70, 142\n",
    "53, 46, 55, 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "xy = np.loadtxt('sample1.csv', delimiter=',', dtype=np.float32)\n",
    "x_data = xy[:, :-1]\n",
    "y_data = xy[:, [-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 3) \n",
      " [[ 73.  80.  75.]\n",
      " [ 93.  88.  93.]\n",
      " [ 89.  91.  90.]\n",
      " [ 96.  98. 100.]\n",
      " [ 73.  66.  70.]\n",
      " [ 53.  46.  55.]] 6\n",
      "(6, 1) \n",
      " [[152.]\n",
      " [185.]\n",
      " [180.]\n",
      " [196.]\n",
      " [142.]\n",
      " [101.]]\n"
     ]
    }
   ],
   "source": [
    "print(x_data.shape, \"\\n\", x_data, len(x_data))\n",
    "print(y_data.shape, \"\\n\", y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost: 3212.1716 \n",
      "Prediction: [[ 95.60658 ]\n",
      " [121.32763 ]\n",
      " [116.08104 ]\n",
      " [127.0178  ]\n",
      " [ 93.876305]\n",
      " [ 71.359276]]\n",
      "20 Cost: 8.525262 \n",
      "Prediction: [[148.755   ]\n",
      " [185.18575 ]\n",
      " [179.01323 ]\n",
      " [195.54694 ]\n",
      " [142.58044 ]\n",
      " [107.250694]]\n",
      "40 Cost: 8.442075 \n",
      "Prediction: [[148.78159]\n",
      " [185.17722]\n",
      " [179.02617]\n",
      " [195.55545]\n",
      " [142.56845]\n",
      " [107.22846]]\n",
      "60 Cost: 8.3599615 \n",
      "Prediction: [[148.80559]\n",
      " [185.16586]\n",
      " [179.03616]\n",
      " [195.56079]\n",
      " [142.55432]\n",
      " [107.20474]]\n",
      "80 Cost: 8.278927 \n",
      "Prediction: [[148.8294 ]\n",
      " [185.15456]\n",
      " [179.04608]\n",
      " [195.56607]\n",
      " [142.5403 ]\n",
      " [107.18117]]\n",
      "100 Cost: 8.198906 \n",
      "Prediction: [[148.85309]\n",
      " [185.14333]\n",
      " [179.05592]\n",
      " [195.57132]\n",
      " [142.52637]\n",
      " [107.15774]]\n",
      "120 Cost: 8.1199255 \n",
      "Prediction: [[148.8766 ]\n",
      " [185.13219]\n",
      " [179.0657 ]\n",
      " [195.5765 ]\n",
      " [142.51254]\n",
      " [107.13445]]\n",
      "140 Cost: 8.041961 \n",
      "Prediction: [[148.89996]\n",
      " [185.12111]\n",
      " [179.07544]\n",
      " [195.58168]\n",
      " [142.49883]\n",
      " [107.11132]]\n",
      "160 Cost: 7.964996 \n",
      "Prediction: [[148.92319]\n",
      " [185.11012]\n",
      " [179.08511]\n",
      " [195.58679]\n",
      " [142.4852 ]\n",
      " [107.08834]]\n",
      "180 Cost: 7.8890433 \n",
      "Prediction: [[148.94623]\n",
      " [185.09918]\n",
      " [179.0947 ]\n",
      " [195.59187]\n",
      " [142.47168]\n",
      " [107.0655 ]]\n",
      "200 Cost: 7.814026 \n",
      "Prediction: [[148.96915]\n",
      " [185.08835]\n",
      " [179.10425]\n",
      " [195.59692]\n",
      " [142.45825]\n",
      " [107.0428 ]]\n",
      "220 Cost: 7.740017 \n",
      "Prediction: [[148.99188]\n",
      " [185.07758]\n",
      " [179.11372]\n",
      " [195.6019 ]\n",
      " [142.44492]\n",
      " [107.02025]]\n",
      "240 Cost: 7.666916 \n",
      "Prediction: [[149.0145 ]\n",
      " [185.06686]\n",
      " [179.12314]\n",
      " [195.60686]\n",
      " [142.43167]\n",
      " [106.99783]]\n",
      "260 Cost: 7.5947843 \n",
      "Prediction: [[149.03694]\n",
      " [185.05621]\n",
      " [179.13249]\n",
      " [195.61177]\n",
      " [142.41855]\n",
      " [106.97556]]\n",
      "280 Cost: 7.523556 \n",
      "Prediction: [[149.05925]\n",
      " [185.04568]\n",
      " [179.1418 ]\n",
      " [195.61665]\n",
      " [142.40552]\n",
      " [106.95343]]\n",
      "300 Cost: 7.4532623 \n",
      "Prediction: [[149.0814 ]\n",
      " [185.03519]\n",
      " [179.15102]\n",
      " [195.6215 ]\n",
      " [142.39256]\n",
      " [106.93144]]\n",
      "320 Cost: 7.383856 \n",
      "Prediction: [[149.10341 ]\n",
      " [185.02477 ]\n",
      " [179.1602  ]\n",
      " [195.6263  ]\n",
      " [142.37971 ]\n",
      " [106.909584]]\n",
      "340 Cost: 7.3153267 \n",
      "Prediction: [[149.12529]\n",
      " [185.01443]\n",
      " [179.16934]\n",
      " [195.63107]\n",
      " [142.36697]\n",
      " [106.88787]]\n",
      "360 Cost: 7.247675 \n",
      "Prediction: [[149.14702]\n",
      " [185.00415]\n",
      " [179.1784 ]\n",
      " [195.63577]\n",
      " [142.3543 ]\n",
      " [106.86629]]\n",
      "380 Cost: 7.1809144 \n",
      "Prediction: [[149.1686 ]\n",
      " [184.99397]\n",
      " [179.18741]\n",
      " [195.64049]\n",
      " [142.34174]\n",
      " [106.84485]]\n",
      "400 Cost: 7.115017 \n",
      "Prediction: [[149.19003]\n",
      " [184.98383]\n",
      " [179.19633]\n",
      " [195.64513]\n",
      " [142.32925]\n",
      " [106.82355]]\n",
      "420 Cost: 7.0499153 \n",
      "Prediction: [[149.21133]\n",
      " [184.97375]\n",
      " [179.20523]\n",
      " [195.64973]\n",
      " [142.31688]\n",
      " [106.80236]]\n",
      "440 Cost: 6.985668 \n",
      "Prediction: [[149.23248]\n",
      " [184.96375]\n",
      " [179.21405]\n",
      " [195.6543 ]\n",
      " [142.30457]\n",
      " [106.78131]]\n",
      "460 Cost: 6.922287 \n",
      "Prediction: [[149.2535 ]\n",
      " [184.95384]\n",
      " [179.22284]\n",
      " [195.65886]\n",
      " [142.29237]\n",
      " [106.76042]]\n",
      "480 Cost: 6.859689 \n",
      "Prediction: [[149.27437]\n",
      " [184.94398]\n",
      " [179.23155]\n",
      " [195.66335]\n",
      " [142.28024]\n",
      " [106.73965]]\n",
      "500 Cost: 6.7978606 \n",
      "Prediction: [[149.2951 ]\n",
      " [184.93417]\n",
      " [179.24022]\n",
      " [195.6678 ]\n",
      " [142.26822]\n",
      " [106.71899]]\n",
      "520 Cost: 6.7368355 \n",
      "Prediction: [[149.31572]\n",
      " [184.92445]\n",
      " [179.24883]\n",
      " [195.67224]\n",
      " [142.25629]\n",
      " [106.69847]]\n",
      "540 Cost: 6.676578 \n",
      "Prediction: [[149.3362 ]\n",
      " [184.9148 ]\n",
      " [179.25739]\n",
      " [195.67664]\n",
      " [142.24445]\n",
      " [106.67808]]\n",
      "560 Cost: 6.6171107 \n",
      "Prediction: [[149.35652 ]\n",
      " [184.9052  ]\n",
      " [179.26588 ]\n",
      " [195.68098 ]\n",
      " [142.23268 ]\n",
      " [106.657814]]\n",
      "580 Cost: 6.55841 \n",
      "Prediction: [[149.37672]\n",
      " [184.89568]\n",
      " [179.27432]\n",
      " [195.6853 ]\n",
      " [142.221  ]\n",
      " [106.63769]]\n",
      "600 Cost: 6.5004673 \n",
      "Prediction: [[149.39679]\n",
      " [184.8862 ]\n",
      " [179.28271]\n",
      " [195.6896 ]\n",
      " [142.20941]\n",
      " [106.61769]]\n",
      "620 Cost: 6.4432197 \n",
      "Prediction: [[149.41672]\n",
      " [184.87679]\n",
      " [179.29106]\n",
      " [195.69383]\n",
      " [142.19789]\n",
      " [106.59779]]\n",
      "640 Cost: 6.3867297 \n",
      "Prediction: [[149.43652]\n",
      " [184.86746]\n",
      " [179.29935]\n",
      " [195.69806]\n",
      " [142.18648]\n",
      " [106.57804]]\n",
      "660 Cost: 6.3309517 \n",
      "Prediction: [[149.45619]\n",
      " [184.8582 ]\n",
      " [179.30757]\n",
      " [195.70224]\n",
      " [142.17516]\n",
      " [106.5584 ]]\n",
      "680 Cost: 6.275888 \n",
      "Prediction: [[149.47574 ]\n",
      " [184.84898 ]\n",
      " [179.31575 ]\n",
      " [195.70639 ]\n",
      " [142.16391 ]\n",
      " [106.538895]]\n",
      "700 Cost: 6.2215004 \n",
      "Prediction: [[149.49516]\n",
      " [184.83984]\n",
      " [179.32388]\n",
      " [195.71053]\n",
      " [142.15273]\n",
      " [106.5195 ]]\n",
      "720 Cost: 6.167851 \n",
      "Prediction: [[149.51443]\n",
      " [184.83075]\n",
      " [179.33194]\n",
      " [195.71458]\n",
      " [142.14163]\n",
      " [106.50024]]\n",
      "740 Cost: 6.1148505 \n",
      "Prediction: [[149.5336 ]\n",
      " [184.82173]\n",
      " [179.33997]\n",
      " [195.71863]\n",
      " [142.13063]\n",
      " [106.48109]]\n",
      "760 Cost: 6.062513 \n",
      "Prediction: [[149.55264]\n",
      " [184.81279]\n",
      " [179.34798]\n",
      " [195.72267]\n",
      " [142.11974]\n",
      " [106.46206]]\n",
      "780 Cost: 6.0108857 \n",
      "Prediction: [[149.57155]\n",
      " [184.80388]\n",
      " [179.35588]\n",
      " [195.72664]\n",
      " [142.10889]\n",
      " [106.44316]]\n",
      "800 Cost: 5.959873 \n",
      "Prediction: [[149.59033]\n",
      " [184.79503]\n",
      " [179.36375]\n",
      " [195.73058]\n",
      " [142.09811]\n",
      " [106.42436]]\n",
      "820 Cost: 5.9095473 \n",
      "Prediction: [[149.60898]\n",
      " [184.78625]\n",
      " [179.37155]\n",
      " [195.73448]\n",
      " [142.08743]\n",
      " [106.40569]]\n",
      "840 Cost: 5.859814 \n",
      "Prediction: [[149.62753]\n",
      " [184.77756]\n",
      " [179.37935]\n",
      " [195.7384 ]\n",
      " [142.07684]\n",
      " [106.38714]]\n",
      "860 Cost: 5.8107357 \n",
      "Prediction: [[149.64595]\n",
      " [184.76888]\n",
      " [179.38707]\n",
      " [195.74223]\n",
      " [142.06633]\n",
      " [106.3687 ]]\n",
      "880 Cost: 5.7622924 \n",
      "Prediction: [[149.66422 ]\n",
      " [184.76027 ]\n",
      " [179.39471 ]\n",
      " [195.74603 ]\n",
      " [142.05586 ]\n",
      " [106.350365]]\n",
      "900 Cost: 5.7144146 \n",
      "Prediction: [[149.6824  ]\n",
      " [184.75174 ]\n",
      " [179.40236 ]\n",
      " [195.74985 ]\n",
      " [142.04552 ]\n",
      " [106.332146]]\n",
      "920 Cost: 5.6671944 \n",
      "Prediction: [[149.70045]\n",
      " [184.74326]\n",
      " [179.40993]\n",
      " [195.75359]\n",
      " [142.03522]\n",
      " [106.31406]]\n",
      "940 Cost: 5.620545 \n",
      "Prediction: [[149.7184  ]\n",
      " [184.73485 ]\n",
      " [179.41747 ]\n",
      " [195.75732 ]\n",
      " [142.02502 ]\n",
      " [106.296074]]\n",
      "960 Cost: 5.5745015 \n",
      "Prediction: [[149.7362 ]\n",
      " [184.72647]\n",
      " [179.42493]\n",
      " [195.761  ]\n",
      " [142.01486]\n",
      " [106.2782 ]]\n",
      "980 Cost: 5.5290146 \n",
      "Prediction: [[149.7539 ]\n",
      " [184.71817]\n",
      " [179.43237]\n",
      " [195.76466]\n",
      " [142.0048 ]\n",
      " [106.26043]]\n",
      "1000 Cost: 5.4841366 \n",
      "Prediction: [[149.77148]\n",
      " [184.70988]\n",
      " [179.43974]\n",
      " [195.7683 ]\n",
      " [141.99483]\n",
      " [106.24278]]\n",
      "1020 Cost: 5.439816 \n",
      "Prediction: [[149.78896]\n",
      " [184.7017 ]\n",
      " [179.4471 ]\n",
      " [195.7719 ]\n",
      " [141.98491]\n",
      " [106.22525]]\n",
      "1040 Cost: 5.396052 \n",
      "Prediction: [[149.8063 ]\n",
      " [184.69356]\n",
      " [179.45438]\n",
      " [195.77545]\n",
      " [141.97508]\n",
      " [106.20782]]\n",
      "1060 Cost: 5.352822 \n",
      "Prediction: [[149.82355]\n",
      " [184.68549]\n",
      " [179.46164]\n",
      " [195.779  ]\n",
      " [141.96532]\n",
      " [106.19049]]\n",
      "1080 Cost: 5.3101597 \n",
      "Prediction: [[149.84067]\n",
      " [184.67746]\n",
      " [179.46884]\n",
      " [195.78252]\n",
      " [141.95563]\n",
      " [106.17328]]\n",
      "1100 Cost: 5.268009 \n",
      "Prediction: [[149.8577  ]\n",
      " [184.66948 ]\n",
      " [179.47598 ]\n",
      " [195.78601 ]\n",
      " [141.94603 ]\n",
      " [106.156166]]\n",
      "1120 Cost: 5.2264094 \n",
      "Prediction: [[149.87459]\n",
      " [184.66154]\n",
      " [179.4831 ]\n",
      " [195.78944]\n",
      " [141.93648]\n",
      " [106.13916]]\n",
      "1140 Cost: 5.1853423 \n",
      "Prediction: [[149.89137]\n",
      " [184.65369]\n",
      " [179.49016]\n",
      " [195.79286]\n",
      " [141.927  ]\n",
      " [106.12227]]\n",
      "1160 Cost: 5.144765 \n",
      "Prediction: [[149.90805]\n",
      " [184.64587]\n",
      " [179.49718]\n",
      " [195.79628]\n",
      " [141.91762]\n",
      " [106.10547]]\n",
      "1180 Cost: 5.1047173 \n",
      "Prediction: [[149.92462]\n",
      " [184.6381 ]\n",
      " [179.50415]\n",
      " [195.79964]\n",
      " [141.90828]\n",
      " [106.08878]]\n",
      "1200 Cost: 5.065158 \n",
      "Prediction: [[149.94109]\n",
      " [184.63042]\n",
      " [179.5111 ]\n",
      " [195.80298]\n",
      " [141.89902]\n",
      " [106.0722 ]]\n",
      "1220 Cost: 5.026138 \n",
      "Prediction: [[149.95741]\n",
      " [184.62274]\n",
      " [179.51794]\n",
      " [195.80624]\n",
      " [141.88982]\n",
      " [106.05572]]\n",
      "1240 Cost: 4.9875665 \n",
      "Prediction: [[149.97366]\n",
      " [184.61514]\n",
      " [179.5248 ]\n",
      " [195.80954]\n",
      " [141.8807 ]\n",
      " [106.03934]]\n",
      "1260 Cost: 4.949491 \n",
      "Prediction: [[149.9898 ]\n",
      " [184.6076 ]\n",
      " [179.5316 ]\n",
      " [195.81277]\n",
      " [141.87164]\n",
      " [106.02306]]\n",
      "1280 Cost: 4.911902 \n",
      "Prediction: [[150.00581]\n",
      " [184.6001 ]\n",
      " [179.53835]\n",
      " [195.816  ]\n",
      " [141.86266]\n",
      " [106.00688]]\n",
      "1300 Cost: 4.874758 \n",
      "Prediction: [[150.02176]\n",
      " [184.59265]\n",
      " [179.54507]\n",
      " [195.81921]\n",
      " [141.85376]\n",
      " [105.99081]]\n",
      "1320 Cost: 4.8381066 \n",
      "Prediction: [[150.03757]\n",
      " [184.58527]\n",
      " [179.55173]\n",
      " [195.82237]\n",
      " [141.84491]\n",
      " [105.97483]]\n",
      "1340 Cost: 4.801908 \n",
      "Prediction: [[150.05328 ]\n",
      " [184.57791 ]\n",
      " [179.55835 ]\n",
      " [195.8255  ]\n",
      " [141.83612 ]\n",
      " [105.958954]]\n",
      "1360 Cost: 4.766133 \n",
      "Prediction: [[150.06892]\n",
      " [184.57063]\n",
      " [179.56497]\n",
      " [195.82863]\n",
      " [141.82744]\n",
      " [105.94318]]\n",
      "1380 Cost: 4.7308145 \n",
      "Prediction: [[150.08443]\n",
      " [184.5634 ]\n",
      " [179.57152]\n",
      " [195.83171]\n",
      " [141.81877]\n",
      " [105.92748]]\n",
      "1400 Cost: 4.695975 \n",
      "Prediction: [[150.09982]\n",
      " [184.5562 ]\n",
      " [179.57799]\n",
      " [195.83476]\n",
      " [141.8102 ]\n",
      " [105.9119 ]]\n",
      "1420 Cost: 4.661546 \n",
      "Prediction: [[150.11513 ]\n",
      " [184.54906 ]\n",
      " [179.58447 ]\n",
      " [195.83781 ]\n",
      " [141.80168 ]\n",
      " [105.896416]]\n",
      "1440 Cost: 4.627568 \n",
      "Prediction: [[150.13033]\n",
      " [184.54195]\n",
      " [179.59088]\n",
      " [195.8408 ]\n",
      " [141.79321]\n",
      " [105.88103]]\n",
      "1460 Cost: 4.5939837 \n",
      "Prediction: [[150.14543]\n",
      " [184.5349 ]\n",
      " [179.59726]\n",
      " [195.84378]\n",
      " [141.78484]\n",
      " [105.86572]]\n",
      "1480 Cost: 4.5608277 \n",
      "Prediction: [[150.16045 ]\n",
      " [184.52792 ]\n",
      " [179.6036  ]\n",
      " [195.84674 ]\n",
      " [141.77652 ]\n",
      " [105.850525]]\n",
      "1500 Cost: 4.5280776 \n",
      "Prediction: [[150.17535]\n",
      " [184.52097]\n",
      " [179.60992]\n",
      " [195.84967]\n",
      " [141.76826]\n",
      " [105.83541]]\n",
      "1520 Cost: 4.495757 \n",
      "Prediction: [[150.19016]\n",
      " [184.51405]\n",
      " [179.61617]\n",
      " [195.85257]\n",
      " [141.76006]\n",
      " [105.8204 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1540 Cost: 4.4638047 \n",
      "Prediction: [[150.20488 ]\n",
      " [184.5072  ]\n",
      " [179.62239 ]\n",
      " [195.85544 ]\n",
      " [141.75194 ]\n",
      " [105.805466]]\n",
      "1560 Cost: 4.4322724 \n",
      "Prediction: [[150.2195  ]\n",
      " [184.5004  ]\n",
      " [179.62856 ]\n",
      " [195.85829 ]\n",
      " [141.74385 ]\n",
      " [105.790634]]\n",
      "1580 Cost: 4.401133 \n",
      "Prediction: [[150.234  ]\n",
      " [184.49364]\n",
      " [179.63469]\n",
      " [195.8611 ]\n",
      " [141.73584]\n",
      " [105.77589]]\n",
      "1600 Cost: 4.3703694 \n",
      "Prediction: [[150.24844 ]\n",
      " [184.48692 ]\n",
      " [179.64082 ]\n",
      " [195.86392 ]\n",
      " [141.7279  ]\n",
      " [105.761246]]\n",
      "1620 Cost: 4.340003 \n",
      "Prediction: [[150.26276]\n",
      " [184.48024]\n",
      " [179.64688]\n",
      " [195.86667]\n",
      " [141.72   ]\n",
      " [105.74668]]\n",
      "1640 Cost: 4.3099837 \n",
      "Prediction: [[150.27701]\n",
      " [184.47363]\n",
      " [179.65291]\n",
      " [195.86945]\n",
      " [141.7122 ]\n",
      " [105.73221]]\n",
      "1660 Cost: 4.2803655 \n",
      "Prediction: [[150.29114]\n",
      " [184.46706]\n",
      " [179.65889]\n",
      " [195.87218]\n",
      " [141.70442]\n",
      " [105.71783]]\n",
      "1680 Cost: 4.251105 \n",
      "Prediction: [[150.30519]\n",
      " [184.46053]\n",
      " [179.66486]\n",
      " [195.87488]\n",
      " [141.69672]\n",
      " [105.70354]]\n",
      "1700 Cost: 4.222199 \n",
      "Prediction: [[150.31914]\n",
      " [184.45404]\n",
      " [179.67076]\n",
      " [195.87755]\n",
      " [141.68907]\n",
      " [105.68932]]\n",
      "1720 Cost: 4.1936703 \n",
      "Prediction: [[150.333  ]\n",
      " [184.44759]\n",
      " [179.67665]\n",
      " [195.8802 ]\n",
      " [141.68147]\n",
      " [105.67521]]\n",
      "1740 Cost: 4.165455 \n",
      "Prediction: [[150.34679]\n",
      " [184.4412 ]\n",
      " [179.6825 ]\n",
      " [195.88284]\n",
      " [141.67397]\n",
      " [105.66117]]\n",
      "1760 Cost: 4.1376433 \n",
      "Prediction: [[150.36046]\n",
      " [184.43484]\n",
      " [179.6883 ]\n",
      " [195.88544]\n",
      " [141.66647]\n",
      " [105.64724]]\n",
      "1780 Cost: 4.1101255 \n",
      "Prediction: [[150.37405]\n",
      " [184.42854]\n",
      " [179.69405]\n",
      " [195.88803]\n",
      " [141.65907]\n",
      " [105.63337]]\n",
      "1800 Cost: 4.08295 \n",
      "Prediction: [[150.38757]\n",
      " [184.42227]\n",
      " [179.69978]\n",
      " [195.89058]\n",
      " [141.65173]\n",
      " [105.61959]]\n",
      "1820 Cost: 4.0561547 \n",
      "Prediction: [[150.40097]\n",
      " [184.41605]\n",
      " [179.70547]\n",
      " [195.89313]\n",
      " [141.64441]\n",
      " [105.60591]]\n",
      "1840 Cost: 4.0296545 \n",
      "Prediction: [[150.41429]\n",
      " [184.40987]\n",
      " [179.71114]\n",
      " [195.89565]\n",
      " [141.63718]\n",
      " [105.5923 ]]\n",
      "1860 Cost: 4.003485 \n",
      "Prediction: [[150.42754]\n",
      " [184.40373]\n",
      " [179.71677]\n",
      " [195.89813]\n",
      " [141.63   ]\n",
      " [105.57878]]\n",
      "1880 Cost: 3.9776247 \n",
      "Prediction: [[150.44069]\n",
      " [184.39763]\n",
      " [179.72235]\n",
      " [195.90059]\n",
      " [141.62286]\n",
      " [105.56533]]\n",
      "1900 Cost: 3.9520833 \n",
      "Prediction: [[150.45377]\n",
      " [184.39159]\n",
      " [179.7279 ]\n",
      " [195.90303]\n",
      " [141.6158 ]\n",
      " [105.55197]]\n",
      "1920 Cost: 3.9268868 \n",
      "Prediction: [[150.46674 ]\n",
      " [184.38556 ]\n",
      " [179.73343 ]\n",
      " [195.90546 ]\n",
      " [141.60878 ]\n",
      " [105.538704]]\n",
      "1940 Cost: 3.9019642 \n",
      "Prediction: [[150.47963]\n",
      " [184.3796 ]\n",
      " [179.73889]\n",
      " [195.90785]\n",
      " [141.6018 ]\n",
      " [105.5255 ]]\n",
      "1960 Cost: 3.8773706 \n",
      "Prediction: [[150.49243]\n",
      " [184.37367]\n",
      " [179.74435]\n",
      " [195.91023]\n",
      " [141.59491]\n",
      " [105.51239]]\n",
      "1980 Cost: 3.8530636 \n",
      "Prediction: [[150.50516]\n",
      " [184.36778]\n",
      " [179.74977]\n",
      " [195.91258]\n",
      " [141.58804]\n",
      " [105.49935]]\n",
      "2000 Cost: 3.8290513 \n",
      "Prediction: [[150.5178 ]\n",
      " [184.36194]\n",
      " [179.75516]\n",
      " [195.91493]\n",
      " [141.58125]\n",
      " [105.4864 ]]\n"
     ]
    }
   ],
   "source": [
    "n, m = x_data.shape\n",
    "\n",
    "# make sure the shape and data are OK\n",
    "X = tf.placeholder(tf.float32, shape=[None, m])  # NONE을 설정해 놓아야 나중에 predict 할때 표본 값을 자유롭게 넣을 수 있다.\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([m, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# model\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# cost function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "    \n",
    "    if step % 20 == 0:\n",
    "        print(step, \"Cost:\", cost_val, \"\\nPrediction:\", hy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[152.],\n",
       "       [185.],\n",
       "       [180.],\n",
       "       [196.],\n",
       "       [142.],\n",
       "       [101.]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your score will be  [[189.70505]]\n"
     ]
    }
   ],
   "source": [
    "# predict my score\n",
    "print(\"Your score will be \", sess.run(hypothesis, feed_dict={X: [[100, 70, 101]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other score will be  [[161.39798]\n",
      " [176.56564]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Other score will be \", sess.run(hypothesis, feed_dict={X: [[60, 70, 110], [90, 100, 80]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queue Runners\n",
    "\n",
    "그림 : https://mblogthumb-phinf.pstatic.net/MjAxNzAzMjFfMTA4/MDAxNDkwMDg0Njk3MTA5.qfcnDscM6Zf1MXOtNMvzElwm6cvOII0Q9EWBOFj4Me0g.VODO8qxcxAJ-hhkWw6y5VMhVsy_pTFSskp86dlu-sTcg.JPEG.ishkkman/1.jpg?type=w800\n",
    "\n",
    "* step 1: 파일 리스트 만들기\n",
    "\n",
    "    + filenames_queue = tf.train.string_input_producer(['data-01-test-score.csv', 'data-02-test-score.csv', 'data-03-test-score.csv', ...], shuffle=False, name='filename_queue')\n",
    "\n",
    "* step 2: 파일을 읽어올 reader 정의. tf.TextLineReader() 텍스트를 읽어올때 사용\n",
    "    + reader = tf.TextLineReader()\n",
    "    + key, value = reader.read(filename_queue)\n",
    "        \n",
    "* step 3:\n",
    "    + record_defaults = [[0.], [0.], [0.]]  # 데이터 타입을 설정하기 위해 디폴트 값을 이렇게 정한다.\n",
    "    + xy = tf.decode_csv(value, record_defaults=record_defaults)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "step 4: tf.train.batch()를 이용해 배치 실행\n",
    "\n",
    "# collect batches of csv\n",
    "train_x_batch, train_y_batch = tf.train.batch([xy[0:-1], xy[-1:]], batch_size=10)\n",
    "sess = tf.Session()\n",
    "...\n",
    "\n",
    "# start populating the filename queue\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "for step in range(2001):\n",
    "    x_batch, y_batch = sess.run([train_x_batch, train_y_batch])\n",
    "    ...\n",
    "    \n",
    "coord.request_stop()\n",
    "coord.join(threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queue Runner 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, Field 0 in record 0 is not a valid float: #EXAM1\n",
      "\t [[{{node DecodeCSV}}]]\n"
     ]
    },
    {
     "ename": "OutOfRangeError",
     "evalue": "FIFOQueue '_27_batch_3/fifo_queue' is closed and has insufficient elements (requested 10, current size 0)\n\t [[node batch_3 (defined at <ipython-input-27-2f959873d877>:13) ]]\n\nCaused by op 'batch_3', defined at:\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/asyncio/base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/asyncio/base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-27-2f959873d877>\", line 13, in <module>\n    train_x_batch, train_y_batch = tf.train.batch([xy[0:-1], xy[-1:]], batch_size=10)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 324, in new_func\n    return func(*args, **kwargs)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/input.py\", line 1019, in batch\n    name=name)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/input.py\", line 789, in _batch\n    dequeued = queue.dequeue_many(batch_size, name=name)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/data_flow_ops.py\", line 488, in dequeue_many\n    self._queue_ref, n=n, component_types=self._dtypes, name=name)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 3645, in queue_dequeue_many_v2\n    timeout_ms=timeout_ms, name=name)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nOutOfRangeError (see above for traceback): FIFOQueue '_27_batch_3/fifo_queue' is closed and has insufficient elements (requested 10, current size 0)\n\t [[node batch_3 (defined at <ipython-input-27-2f959873d877>:13) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfRangeError\u001b[0m: FIFOQueue '_27_batch_3/fifo_queue' is closed and has insufficient elements (requested 10, current size 0)\n\t [[{{node batch_3}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-2f959873d877>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_x_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mcost_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhy_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypothesis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfRangeError\u001b[0m: FIFOQueue '_27_batch_3/fifo_queue' is closed and has insufficient elements (requested 10, current size 0)\n\t [[node batch_3 (defined at <ipython-input-27-2f959873d877>:13) ]]\n\nCaused by op 'batch_3', defined at:\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/asyncio/base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/asyncio/base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-27-2f959873d877>\", line 13, in <module>\n    train_x_batch, train_y_batch = tf.train.batch([xy[0:-1], xy[-1:]], batch_size=10)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 324, in new_func\n    return func(*args, **kwargs)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/input.py\", line 1019, in batch\n    name=name)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/input.py\", line 789, in _batch\n    dequeued = queue.dequeue_many(batch_size, name=name)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/data_flow_ops.py\", line 488, in dequeue_many\n    self._queue_ref, n=n, component_types=self._dtypes, name=name)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 3645, in queue_dequeue_many_v2\n    timeout_ms=timeout_ms, name=name)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/Users/imjunghee/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nOutOfRangeError (see above for traceback): FIFOQueue '_27_batch_3/fifo_queue' is closed and has insufficient elements (requested 10, current size 0)\n\t [[node batch_3 (defined at <ipython-input-27-2f959873d877>:13) ]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "filename_queue = tf.train.string_input_producer(['sample1.csv'], shuffle=False, name='filename_queue')\n",
    "reader = tf.TextLineReader()\n",
    "key, value = reader.read(filename_queue)\n",
    "\n",
    "# Default values\n",
    "# decoded result\n",
    "record_defaults = [[0.], [0.], [0.], [0.]]\n",
    "xy = tf.decode_csv(value, record_defaults=record_defaults)\n",
    "\n",
    "# collect batches of csv\n",
    "train_x_batch, train_y_batch = tf.train.batch([xy[0:-1], xy[-1:]], batch_size=10)\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# model\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# cost function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# start populating the filename queue\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "for step in range(2001):\n",
    "    x_batch, y_batch = sess.run([train_x_batch, train_y_batch])\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train], feed_dict={X: x_batch, Y: y_batch})\n",
    "    \n",
    "    if step % 20 == 0:\n",
    "        print(step, \"Cost:\", cost_val, \"\\nPrediction:\\n\", hy_val)\n",
    "\n",
    "coord.request_stop()\n",
    "coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
