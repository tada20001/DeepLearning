{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.font_manager as fm\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "path = \"/Library/Fonts/NanumGothic.otf\"\n",
    "font_name = fm.FontProperties(fname=path, size=20).get_name()\n",
    "\n",
    "plt.rc('font', family=font_name)\n",
    "fm._rebuild()\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Hypothesis\n",
    "\n",
    "$$H(x) = Wx + b$$\n",
    "\n",
    "H(x) 값을 0 ~ 1사이로 만드는 함수 g(z),\n",
    "\n",
    "z = H(x)이고, z가 어떤 값이 되든 항상 0~1사이의 분포를 갖는다.  이것이 logistic function 또는 sigmoid function이다.\n",
    "\n",
    "이 함수는 z 값이 커질 수록 1(g(z)=1)에 가까워지고, z 값이 작아질 수록 0(g(z)=0)에 가까워지는 함수이다.\n",
    "\n",
    "$$ z = w^Tx $$\n",
    "\n",
    "$$\\text{logitstic}(x) = H(x) = \\dfrac{1}{1+\\exp{(-w^Tx)}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost\n",
    "\n",
    "Logistic Regression의 경우, cost 함수 분포는 오목한 형태가 되지 않고, 울퉁불퉁한 곡선의 형태가 된다.\n",
    "\n",
    "즉, cost 함수에 local minimum이 존재하게 되어 Gradient Descent Algorithm을 여기에서는 사용할 수 없다.\n",
    "\n",
    "결과적으로 새로운 cost 함수는 다음과 같다.\n",
    "\n",
    "$$ C(H(x), y) = \\begin{cases} -log(H(x)) & \\text{ if } y = 1 \\\\ -log(1-H(x)) & \\text{ if } y = 0 \\end{cases}$$\n",
    "\n",
    "y=1일 때 예측한 값이 같아지면,  cost 함수 g(z)는 0으로 수렴하고, 실제 값 y = 0일 때도 예측한 값이 0에 가까워지면 cost 함수 g(z)도 0으로 수렴한다. \n",
    "\n",
    "반대로 예측이 틀리면 cost 함수 값은 무한대로 발산하는 값을 갖는다.\n",
    "\n",
    "위의 식을 일반화하면,\n",
    "$$C(H(x), y) = ylog(H(x))-(1-y)log(1-H(x))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimize cost - Gradient Descent alogrithm\n",
    "\n",
    "여기에서도 마찬가지로 Gradient Descent Algorithm을 사용할 수 있고, \n",
    "\n",
    "$$\\text{cost}(W) = \\dfrac{1}{m}\\sum \\ ylog(H(x)) + (1 - y)log(1-H(x))$$\n",
    "\n",
    "weight를 업데이트 혹은 구하기 위해서는 다음과 같은 cost 함수의 미분 값이 필요하다.\n",
    "\n",
    "$$ W:= W-\\alpha \\dfrac{\\partial}{\\partial w}\\text{cost}(W)$$\n",
    "\n",
    "위의 코스트 함수를 tensorflow를 사용한 코드는 다음과 같다.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cost = tf.reduce_mean(-(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis)))  \n",
    "\n",
    "# minimize\n",
    "a = tf.Variable(0.1)  # learning rate, alpha\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=a)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예제 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.67585\n",
      "200 0.5249104\n",
      "400 0.5059943\n",
      "600 0.48792645\n",
      "800 0.47067872\n",
      "1000 0.4542272\n",
      "1200 0.438547\n",
      "1400 0.42361143\n",
      "1600 0.40939245\n",
      "1800 0.39586127\n",
      "2000 0.38298845\n",
      "2200 0.37074432\n",
      "2400 0.35909894\n",
      "2600 0.34802306\n",
      "2800 0.33748773\n",
      "3000 0.32746473\n",
      "3200 0.31792656\n",
      "3400 0.30884734\n",
      "3600 0.3002015\n",
      "3800 0.29196495\n",
      "4000 0.28411472\n",
      "4200 0.27662888\n",
      "4400 0.26948693\n",
      "4600 0.26266918\n",
      "4800 0.25615737\n",
      "5000 0.24993402\n",
      "5200 0.24398284\n",
      "5400 0.23828839\n",
      "5600 0.23283641\n",
      "5800 0.22761329\n",
      "6000 0.22260642\n",
      "6200 0.21780388\n",
      "6400 0.21319449\n",
      "6600 0.20876785\n",
      "6800 0.20451404\n",
      "7000 0.20042409\n",
      "7200 0.19648926\n",
      "7400 0.19270158\n",
      "7600 0.1890534\n",
      "7800 0.18553759\n",
      "8000 0.18214752\n",
      "8200 0.178877\n",
      "8400 0.17571999\n",
      "8600 0.1726711\n",
      "8800 0.16972496\n",
      "9000 0.1668769\n",
      "9200 0.16412215\n",
      "9400 0.16145642\n",
      "9600 0.15887563\n",
      "9800 0.15637596\n",
      "10000 0.15395372\n",
      "\n",
      "Hypothesis:  [[0.03263738]\n",
      " [0.16133943]\n",
      " [0.31382307]\n",
      " [0.77732116]\n",
      " [0.93698716]\n",
      " [0.9793046 ]] \n",
      "Prediction(Y):\n",
      "  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] \n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
    "y_data = [[0], [0], [0], [1], [1], [1]]\n",
    "\n",
    "# placeholders \n",
    "X = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "# Variables\n",
    "W = tf.Variable(tf.random_normal([2, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# model\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "# cost/loss function\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "\n",
    "# Minimize/train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "# Accuracy computation\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)  # 예측값이 0.5보다 크면 1, 아니면 0\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))  # 예측값과 실제 값이 같으면 1, 아니면 0을 산출하고 이를 평균낸 값 산출\n",
    "\n",
    "# Launch the graph in a session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(10001):\n",
    "    cost_val, _ = sess.run([cost, train], feed_dict={X: x_data, Y: y_data})\n",
    "    if step % 200 == 0:\n",
    "        print(step, cost_val)\n",
    "        \n",
    "# Accuracy Report\n",
    "h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X: x_data, Y: y_data})\n",
    "print(\"\\nHypothesis: \", h, \"\\nPrediction(Y):\\n \", c, \"\\nAccuracy: \", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예제2. Classifying diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.loadtxt('data-03-diabetes.csv', delimiter=',', dtype=np.float32)\n",
    "x_data = xy[:, :-1]\n",
    "y_data = xy[:, [-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((759, 8), (759, 1))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.shape, y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.1866201\n",
      "200 0.7620891\n",
      "400 0.68429416\n",
      "600 0.659299\n",
      "800 0.6430997\n",
      "1000 0.6293665\n",
      "1200 0.61701906\n",
      "1400 0.6057947\n",
      "1600 0.5955708\n",
      "1800 0.58625275\n",
      "2000 0.5777571\n",
      "2200 0.5700069\n",
      "2400 0.56293213\n",
      "2600 0.5564691\n",
      "2800 0.55055946\n",
      "3000 0.54515064\n",
      "3200 0.540195\n",
      "3400 0.53564966\n",
      "3600 0.53147566\n",
      "3800 0.5276385\n",
      "4000 0.5241065\n",
      "4200 0.52085155\n",
      "4400 0.5178485\n",
      "4600 0.5150744\n",
      "4800 0.5125087\n",
      "5000 0.51013315\n",
      "5200 0.50793093\n",
      "5400 0.50588727\n",
      "5600 0.50398856\n",
      "5800 0.5022227\n",
      "6000 0.5005785\n",
      "6200 0.49904615\n",
      "6400 0.4976164\n",
      "6600 0.49628127\n",
      "6800 0.4950332\n",
      "7000 0.49386543\n",
      "7200 0.4927718\n",
      "7400 0.4917467\n",
      "7600 0.49078494\n",
      "7800 0.48988196\n",
      "8000 0.4890335\n",
      "8200 0.48823544\n",
      "8400 0.48748434\n",
      "8600 0.4867768\n",
      "8800 0.48610976\n",
      "9000 0.48548067\n",
      "9200 0.48488688\n",
      "9400 0.48432583\n",
      "9600 0.48379543\n",
      "9800 0.48329383\n",
      "10000 0.48281896\n",
      "\n",
      "Hypothesis:  [[0.4305743 ]\n",
      " [0.9278971 ]\n",
      " [0.18831357]\n",
      " [0.94567287]\n",
      " [0.21201408]\n",
      " [0.7395502 ]\n",
      " [0.92856   ]\n",
      " [0.52209735]\n",
      " [0.24804205]\n",
      " [0.5655194 ]\n",
      " [0.7304999 ]\n",
      " [0.15707946]\n",
      " [0.31684166]\n",
      " [0.2974897 ]\n",
      " [0.7188114 ]\n",
      " [0.47718573]\n",
      " [0.7104234 ]\n",
      " [0.8260877 ]\n",
      " [0.82979935]\n",
      " [0.64245665]\n",
      " [0.69739544]\n",
      " [0.11183205]\n",
      " [0.621315  ]\n",
      " [0.6208248 ]\n",
      " [0.35890472]\n",
      " [0.9323096 ]\n",
      " [0.49985015]\n",
      " [0.678307  ]\n",
      " [0.7472155 ]\n",
      " [0.46407726]\n",
      " [0.94077146]\n",
      " [0.8689494 ]\n",
      " [0.5748148 ]\n",
      " [0.83060396]\n",
      " [0.3333606 ]\n",
      " [0.6649793 ]\n",
      " [0.83990115]\n",
      " [0.6555329 ]\n",
      " [0.40200526]\n",
      " [0.40578836]\n",
      " [0.83899367]\n",
      " [0.20493695]\n",
      " [0.35827458]\n",
      " [0.07358938]\n",
      " [0.5703131 ]\n",
      " [0.93697584]\n",
      " [0.692183  ]\n",
      " [0.6739372 ]\n",
      " [0.9383868 ]\n",
      " [0.9232168 ]\n",
      " [0.9212996 ]\n",
      " [0.2533604 ]\n",
      " [0.353962  ]\n",
      " [0.9640955 ]\n",
      " [0.18036258]\n",
      " [0.54506916]\n",
      " [0.19189265]\n",
      " [0.65688103]\n",
      " [0.8850172 ]\n",
      " [0.47541428]\n",
      " [0.9514292 ]\n",
      " [0.690571  ]\n",
      " [0.6406742 ]\n",
      " [0.8434516 ]\n",
      " [0.6396271 ]\n",
      " [0.70452034]\n",
      " [0.95210844]\n",
      " [0.67422664]\n",
      " [0.8698077 ]\n",
      " [0.6254678 ]\n",
      " [0.27929705]\n",
      " [0.7161852 ]\n",
      " [0.925494  ]\n",
      " [0.9088664 ]\n",
      " [0.89035875]\n",
      " [0.7911656 ]\n",
      " [0.36807805]\n",
      " [0.8549267 ]\n",
      " [0.8580712 ]\n",
      " [0.9125296 ]\n",
      " [0.87666416]\n",
      " [0.7781129 ]\n",
      " [0.4383143 ]\n",
      " [0.8315271 ]\n",
      " [0.48712337]\n",
      " [0.8708561 ]\n",
      " [0.3322392 ]\n",
      " [0.89074475]\n",
      " [0.9419486 ]\n",
      " [0.77817166]\n",
      " [0.8197881 ]\n",
      " [0.67794085]\n",
      " [0.7630905 ]\n",
      " [0.5536841 ]\n",
      " [0.8934164 ]\n",
      " [0.9708834 ]\n",
      " [0.8601209 ]\n",
      " [0.6629625 ]\n",
      " [0.3173037 ]\n",
      " [0.60629344]\n",
      " [0.63790053]\n",
      " [0.95851874]\n",
      " [0.8124502 ]\n",
      " [0.7876819 ]\n",
      " [0.91777056]\n",
      " [0.6462102 ]\n",
      " [0.91358787]\n",
      " [0.80311567]\n",
      " [0.45151904]\n",
      " [0.3284769 ]\n",
      " [0.93202376]\n",
      " [0.8702401 ]\n",
      " [0.37869644]\n",
      " [0.5234068 ]\n",
      " [0.62911063]\n",
      " [0.82613826]\n",
      " [0.8521768 ]\n",
      " [0.92410624]\n",
      " [0.1442762 ]\n",
      " [0.6905942 ]\n",
      " [0.85480237]\n",
      " [0.66146183]\n",
      " [0.5937477 ]\n",
      " [0.79736215]\n",
      " [0.7100065 ]\n",
      " [0.8213163 ]\n",
      " [0.8462068 ]\n",
      " [0.6755099 ]\n",
      " [0.47053945]\n",
      " [0.4080188 ]\n",
      " [0.39896518]\n",
      " [0.7832061 ]\n",
      " [0.933619  ]\n",
      " [0.8069687 ]\n",
      " [0.79045135]\n",
      " [0.8168201 ]\n",
      " [0.4560139 ]\n",
      " [0.7839566 ]\n",
      " [0.75997293]\n",
      " [0.7477437 ]\n",
      " [0.85932124]\n",
      " [0.5958699 ]\n",
      " [0.51051205]\n",
      " [0.71836257]\n",
      " [0.90617037]\n",
      " [0.7992981 ]\n",
      " [0.48871928]\n",
      " [0.92453355]\n",
      " [0.6472275 ]\n",
      " [0.775135  ]\n",
      " [0.3016702 ]\n",
      " [0.43981683]\n",
      " [0.10489556]\n",
      " [0.2601292 ]\n",
      " [0.9158429 ]\n",
      " [0.8749062 ]\n",
      " [0.93880904]\n",
      " [0.09457055]\n",
      " [0.54083973]\n",
      " [0.7692311 ]\n",
      " [0.58235574]\n",
      " [0.87973535]\n",
      " [0.44314244]\n",
      " [0.8160583 ]\n",
      " [0.577691  ]\n",
      " [0.6615155 ]\n",
      " [0.72489697]\n",
      " [0.877792  ]\n",
      " [0.76931226]\n",
      " [0.6019353 ]\n",
      " [0.89409995]\n",
      " [0.8910338 ]\n",
      " [0.9506475 ]\n",
      " [0.20902151]\n",
      " [0.8319874 ]\n",
      " [0.2935274 ]\n",
      " [0.4108047 ]\n",
      " [0.4674282 ]\n",
      " [0.8738388 ]\n",
      " [0.62839687]\n",
      " [0.93244886]\n",
      " [0.89770645]\n",
      " [0.5921371 ]\n",
      " [0.13604283]\n",
      " [0.19368675]\n",
      " [0.7213657 ]\n",
      " [0.72626346]\n",
      " [0.61591375]\n",
      " [0.8297571 ]\n",
      " [0.5840856 ]\n",
      " [0.3248629 ]\n",
      " [0.19973442]\n",
      " [0.87519264]\n",
      " [0.38791877]\n",
      " [0.87149215]\n",
      " [0.8898181 ]\n",
      " [0.73279935]\n",
      " [0.5868702 ]\n",
      " [0.6604286 ]\n",
      " [0.5981528 ]\n",
      " [0.6978085 ]\n",
      " [0.9396961 ]\n",
      " [0.7807828 ]\n",
      " [0.7998928 ]\n",
      " [0.13634065]\n",
      " [0.36993146]\n",
      " [0.9145436 ]\n",
      " [0.2040348 ]\n",
      " [0.929353  ]\n",
      " [0.2671808 ]\n",
      " [0.27575833]\n",
      " [0.4150632 ]\n",
      " [0.6858957 ]\n",
      " [0.19320577]\n",
      " [0.7359688 ]\n",
      " [0.6965828 ]\n",
      " [0.8444305 ]\n",
      " [0.66974574]\n",
      " [0.15488777]\n",
      " [0.46580943]\n",
      " [0.66525555]\n",
      " [0.5270999 ]\n",
      " [0.9254479 ]\n",
      " [0.93627787]\n",
      " [0.66642845]\n",
      " [0.34610566]\n",
      " [0.06244019]\n",
      " [0.6123963 ]\n",
      " [0.39751527]\n",
      " [0.4762663 ]\n",
      " [0.9549222 ]\n",
      " [0.63424355]\n",
      " [0.945196  ]\n",
      " [0.22789118]\n",
      " [0.14056134]\n",
      " [0.27647215]\n",
      " [0.73871   ]\n",
      " [0.9215919 ]\n",
      " [0.8766099 ]\n",
      " [0.60561764]\n",
      " [0.66904545]\n",
      " [0.5968752 ]\n",
      " [0.17163852]\n",
      " [0.50762707]\n",
      " [0.13641042]\n",
      " [0.53278494]\n",
      " [0.87330246]\n",
      " [0.6252066 ]\n",
      " [0.7199271 ]\n",
      " [0.9482174 ]\n",
      " [0.7818832 ]\n",
      " [0.748121  ]\n",
      " [0.79915893]\n",
      " [0.76361   ]\n",
      " [0.8446003 ]\n",
      " [0.34947667]\n",
      " [0.37254456]\n",
      " [0.5236834 ]\n",
      " [0.82331026]\n",
      " [0.6897379 ]\n",
      " [0.66724265]\n",
      " [0.8419838 ]\n",
      " [0.30872262]\n",
      " [0.54636097]\n",
      " [0.63137376]\n",
      " [0.5981716 ]\n",
      " [0.48729047]\n",
      " [0.90085614]\n",
      " [0.7732582 ]\n",
      " [0.94632775]\n",
      " [0.51564384]\n",
      " [0.8003354 ]\n",
      " [0.77689457]\n",
      " [0.7790494 ]\n",
      " [0.72251046]\n",
      " [0.8646553 ]\n",
      " [0.3133909 ]\n",
      " [0.54057366]\n",
      " [0.6706199 ]\n",
      " [0.35769218]\n",
      " [0.84036505]\n",
      " [0.32413578]\n",
      " [0.69127   ]\n",
      " [0.9207287 ]\n",
      " [0.77523875]\n",
      " [0.86711204]\n",
      " [0.6636493 ]\n",
      " [0.58389544]\n",
      " [0.6462997 ]\n",
      " [0.35395622]\n",
      " [0.4322519 ]\n",
      " [0.6353353 ]\n",
      " [0.6020082 ]\n",
      " [0.60887265]\n",
      " [0.65458345]\n",
      " [0.18831518]\n",
      " [0.65273774]\n",
      " [0.9088496 ]\n",
      " [0.54966825]\n",
      " [0.6178058 ]\n",
      " [0.76914525]\n",
      " [0.4030811 ]\n",
      " [0.66957724]\n",
      " [0.51333535]\n",
      " [0.7351028 ]\n",
      " [0.8934138 ]\n",
      " [0.63697547]\n",
      " [0.680935  ]\n",
      " [0.8414992 ]\n",
      " [0.6203635 ]\n",
      " [0.8494127 ]\n",
      " [0.938488  ]\n",
      " [0.2924351 ]\n",
      " [0.7719277 ]\n",
      " [0.23709041]\n",
      " [0.75101876]\n",
      " [0.80375195]\n",
      " [0.6508522 ]\n",
      " [0.33434153]\n",
      " [0.81249404]\n",
      " [0.70667434]\n",
      " [0.7664332 ]\n",
      " [0.14724326]\n",
      " [0.83048594]\n",
      " [0.8299048 ]\n",
      " [0.6242131 ]\n",
      " [0.933473  ]\n",
      " [0.26669657]\n",
      " [0.65145946]\n",
      " [0.9409474 ]\n",
      " [0.19284663]\n",
      " [0.48774904]\n",
      " [0.7025305 ]\n",
      " [0.3270609 ]\n",
      " [0.18004629]\n",
      " [0.83651686]\n",
      " [0.9281138 ]\n",
      " [0.86264545]\n",
      " [0.63708967]\n",
      " [0.69707745]\n",
      " [0.59180397]\n",
      " [0.7401211 ]\n",
      " [0.78647983]\n",
      " [0.9213788 ]\n",
      " [0.7621877 ]\n",
      " [0.7850498 ]\n",
      " [0.59165716]\n",
      " [0.94782174]\n",
      " [0.93985105]\n",
      " [0.7972867 ]\n",
      " [0.2688187 ]\n",
      " [0.707422  ]\n",
      " [0.3121649 ]\n",
      " [0.7367969 ]\n",
      " [0.23274317]\n",
      " [0.22419524]\n",
      " [0.4347596 ]\n",
      " [0.7808664 ]\n",
      " [0.45268512]\n",
      " [0.55805707]\n",
      " [0.8258985 ]\n",
      " [0.6291409 ]\n",
      " [0.8286047 ]\n",
      " [0.94777226]\n",
      " [0.8016844 ]\n",
      " [0.15427327]\n",
      " [0.542803  ]\n",
      " [0.83963025]\n",
      " [0.8458654 ]\n",
      " [0.68812966]\n",
      " [0.28997874]\n",
      " [0.8556417 ]\n",
      " [0.8998539 ]\n",
      " [0.308359  ]\n",
      " [0.69100636]\n",
      " [0.8602134 ]\n",
      " [0.7987374 ]\n",
      " [0.8898819 ]\n",
      " [0.91937125]\n",
      " [0.8614832 ]\n",
      " [0.89943033]\n",
      " [0.7003928 ]\n",
      " [0.65698975]\n",
      " [0.59175754]\n",
      " [0.853701  ]\n",
      " [0.89062387]\n",
      " [0.23308563]\n",
      " [0.81965685]\n",
      " [0.8678242 ]\n",
      " [0.36042264]\n",
      " [0.6736946 ]\n",
      " [0.8762673 ]\n",
      " [0.48011044]\n",
      " [0.91169125]\n",
      " [0.2442584 ]\n",
      " [0.82395554]\n",
      " [0.6243019 ]\n",
      " [0.8706908 ]\n",
      " [0.32829902]\n",
      " [0.687333  ]\n",
      " [0.73884374]\n",
      " [0.74211216]\n",
      " [0.10531428]\n",
      " [0.25653213]\n",
      " [0.7186503 ]\n",
      " [0.832491  ]\n",
      " [0.5436907 ]\n",
      " [0.79684055]\n",
      " [0.46829093]\n",
      " [0.35500407]\n",
      " [0.8721112 ]\n",
      " [0.4961287 ]\n",
      " [0.9274274 ]\n",
      " [0.7880268 ]\n",
      " [0.72494334]\n",
      " [0.9282664 ]\n",
      " [0.6678713 ]\n",
      " [0.8173696 ]\n",
      " [0.3312583 ]\n",
      " [0.26893526]\n",
      " [0.7082453 ]\n",
      " [0.4209903 ]\n",
      " [0.45416668]\n",
      " [0.9134073 ]\n",
      " [0.8816905 ]\n",
      " [0.9194724 ]\n",
      " [0.9528445 ]\n",
      " [0.68107367]\n",
      " [0.91583544]\n",
      " [0.31683788]\n",
      " [0.330598  ]\n",
      " [0.46914035]\n",
      " [0.9436724 ]\n",
      " [0.64792246]\n",
      " [0.17916673]\n",
      " [0.92897415]\n",
      " [0.78672457]\n",
      " [0.5953828 ]\n",
      " [0.7850877 ]\n",
      " [0.0363622 ]\n",
      " [0.92512155]\n",
      " [0.7528546 ]\n",
      " [0.7133604 ]\n",
      " [0.71465856]\n",
      " [0.9615678 ]\n",
      " [0.6422649 ]\n",
      " [0.7490659 ]\n",
      " [0.78953004]\n",
      " [0.84996426]\n",
      " [0.13054794]\n",
      " [0.6768981 ]\n",
      " [0.89830303]\n",
      " [0.62515783]\n",
      " [0.7324327 ]\n",
      " [0.9449156 ]\n",
      " [0.8525974 ]\n",
      " [0.88351727]\n",
      " [0.55924565]\n",
      " [0.74153864]\n",
      " [0.9159131 ]\n",
      " [0.7221788 ]\n",
      " [0.5937086 ]\n",
      " [0.32102144]\n",
      " [0.5300714 ]\n",
      " [0.4582153 ]\n",
      " [0.5583669 ]\n",
      " [0.54218066]\n",
      " [0.7484904 ]\n",
      " [0.572611  ]\n",
      " [0.81533194]\n",
      " [0.80674875]\n",
      " [0.69417995]\n",
      " [0.703477  ]\n",
      " [0.4865266 ]\n",
      " [0.5647336 ]\n",
      " [0.92426217]\n",
      " [0.8253299 ]\n",
      " [0.2432698 ]\n",
      " [0.39570767]\n",
      " [0.5623547 ]\n",
      " [0.14066869]\n",
      " [0.8788694 ]\n",
      " [0.1585058 ]\n",
      " [0.9074149 ]\n",
      " [0.9009858 ]\n",
      " [0.82588387]\n",
      " [0.72923434]\n",
      " [0.8820252 ]\n",
      " [0.37050337]\n",
      " [0.75802934]\n",
      " [0.94168794]\n",
      " [0.2643075 ]\n",
      " [0.44916117]\n",
      " [0.8910349 ]\n",
      " [0.8789077 ]\n",
      " [0.6902909 ]\n",
      " [0.8141198 ]\n",
      " [0.8342396 ]\n",
      " [0.7988496 ]\n",
      " [0.25104332]\n",
      " [0.7883789 ]\n",
      " [0.9161438 ]\n",
      " [0.6431845 ]\n",
      " [0.763339  ]\n",
      " [0.64710265]\n",
      " [0.7995345 ]\n",
      " [0.8673601 ]\n",
      " [0.9120512 ]\n",
      " [0.56634927]\n",
      " [0.4436979 ]\n",
      " [0.72224545]\n",
      " [0.7826824 ]\n",
      " [0.9648175 ]\n",
      " [0.7650666 ]\n",
      " [0.6557338 ]\n",
      " [0.41491953]\n",
      " [0.6821627 ]\n",
      " [0.92627627]\n",
      " [0.9505784 ]\n",
      " [0.8746623 ]\n",
      " [0.6483402 ]\n",
      " [0.6343468 ]\n",
      " [0.8021966 ]\n",
      " [0.48858166]\n",
      " [0.8553442 ]\n",
      " [0.78982913]\n",
      " [0.91500765]\n",
      " [0.5814427 ]\n",
      " [0.710409  ]\n",
      " [0.9075859 ]\n",
      " [0.48886842]\n",
      " [0.6184704 ]\n",
      " [0.68152094]\n",
      " [0.7303188 ]\n",
      " [0.70885795]\n",
      " [0.9075445 ]\n",
      " [0.93029445]\n",
      " [0.1991449 ]\n",
      " [0.17587781]\n",
      " [0.72847444]\n",
      " [0.56582904]\n",
      " [0.28388503]\n",
      " [0.8538719 ]\n",
      " [0.90690064]\n",
      " [0.73751545]\n",
      " [0.933656  ]\n",
      " [0.92202103]\n",
      " [0.7192497 ]\n",
      " [0.85161364]\n",
      " [0.69804484]\n",
      " [0.5271797 ]\n",
      " [0.7345092 ]\n",
      " [0.61729926]\n",
      " [0.09962612]\n",
      " [0.9087737 ]\n",
      " [0.8624484 ]\n",
      " [0.7185695 ]\n",
      " [0.9125617 ]\n",
      " [0.88990533]\n",
      " [0.8686436 ]\n",
      " [0.5685676 ]\n",
      " [0.63715315]\n",
      " [0.8952293 ]\n",
      " [0.77262783]\n",
      " [0.83654964]\n",
      " [0.89725363]\n",
      " [0.64643157]\n",
      " [0.7794727 ]\n",
      " [0.8030617 ]\n",
      " [0.64848006]\n",
      " [0.46174017]\n",
      " [0.12602344]\n",
      " [0.2859496 ]\n",
      " [0.792099  ]\n",
      " [0.6084198 ]\n",
      " [0.6740863 ]\n",
      " [0.5801431 ]\n",
      " [0.9292704 ]\n",
      " [0.3975649 ]\n",
      " [0.7843654 ]\n",
      " [0.35671255]\n",
      " [0.8699269 ]\n",
      " [0.39218777]\n",
      " [0.7832121 ]\n",
      " [0.6192069 ]\n",
      " [0.89110214]\n",
      " [0.5996311 ]\n",
      " [0.20704225]\n",
      " [0.80396605]\n",
      " [0.93290323]\n",
      " [0.38938355]\n",
      " [0.8999611 ]\n",
      " [0.8826792 ]\n",
      " [0.8209182 ]\n",
      " [0.8067917 ]\n",
      " [0.4485464 ]\n",
      " [0.28210938]\n",
      " [0.73363906]\n",
      " [0.23805454]\n",
      " [0.94585705]\n",
      " [0.31569952]\n",
      " [0.910326  ]\n",
      " [0.85874796]\n",
      " [0.4040597 ]\n",
      " [0.2335    ]\n",
      " [0.72138184]\n",
      " [0.41822472]\n",
      " [0.8264558 ]\n",
      " [0.70777225]\n",
      " [0.97522014]\n",
      " [0.6130486 ]\n",
      " [0.5603123 ]\n",
      " [0.80279315]\n",
      " [0.86217463]\n",
      " [0.11607903]\n",
      " [0.7517774 ]\n",
      " [0.819045  ]\n",
      " [0.8595472 ]\n",
      " [0.6006342 ]\n",
      " [0.4717246 ]\n",
      " [0.61455244]\n",
      " [0.90080786]\n",
      " [0.62803644]\n",
      " [0.74369496]\n",
      " [0.8032191 ]\n",
      " [0.8498485 ]\n",
      " [0.74782807]\n",
      " [0.5246222 ]\n",
      " [0.79501593]\n",
      " [0.9076593 ]\n",
      " [0.7299278 ]\n",
      " [0.95136476]\n",
      " [0.790753  ]\n",
      " [0.6067368 ]\n",
      " [0.4903251 ]\n",
      " [0.8342866 ]\n",
      " [0.85695314]\n",
      " [0.47810507]\n",
      " [0.6488812 ]\n",
      " [0.17796078]\n",
      " [0.5150751 ]\n",
      " [0.74656475]\n",
      " [0.9381141 ]\n",
      " [0.8322413 ]\n",
      " [0.7091792 ]\n",
      " [0.7425332 ]\n",
      " [0.8808403 ]\n",
      " [0.465225  ]\n",
      " [0.9138721 ]\n",
      " [0.68479884]\n",
      " [0.8883085 ]\n",
      " [0.29113674]\n",
      " [0.12149796]\n",
      " [0.29345477]\n",
      " [0.35284692]\n",
      " [0.67677116]\n",
      " [0.8350841 ]\n",
      " [0.63642186]\n",
      " [0.68920106]\n",
      " [0.80231786]\n",
      " [0.45017824]\n",
      " [0.37982038]\n",
      " [0.91189194]\n",
      " [0.90174305]\n",
      " [0.5151323 ]\n",
      " [0.73406994]\n",
      " [0.16044223]\n",
      " [0.37649345]\n",
      " [0.7001496 ]\n",
      " [0.67214507]\n",
      " [0.89447606]\n",
      " [0.97409666]\n",
      " [0.1814956 ]\n",
      " [0.68996876]\n",
      " [0.63017094]\n",
      " [0.52971786]\n",
      " [0.73558176]\n",
      " [0.702301  ]\n",
      " [0.87800044]\n",
      " [0.7409999 ]\n",
      " [0.562833  ]\n",
      " [0.66986275]\n",
      " [0.1672906 ]\n",
      " [0.71465045]\n",
      " [0.52826667]\n",
      " [0.8994852 ]\n",
      " [0.55900663]\n",
      " [0.53653604]\n",
      " [0.7373913 ]\n",
      " [0.74200237]\n",
      " [0.52613264]\n",
      " [0.76598847]\n",
      " [0.6679845 ]\n",
      " [0.42964622]\n",
      " [0.6269089 ]\n",
      " [0.86749   ]\n",
      " [0.84026384]\n",
      " [0.52378744]\n",
      " [0.74350876]\n",
      " [0.26212507]\n",
      " [0.8580036 ]\n",
      " [0.55259794]\n",
      " [0.7549026 ]\n",
      " [0.38104737]\n",
      " [0.604094  ]\n",
      " [0.83325124]\n",
      " [0.15067697]\n",
      " [0.33521354]\n",
      " [0.8020346 ]\n",
      " [0.81776375]\n",
      " [0.8169776 ]\n",
      " [0.9136149 ]\n",
      " [0.81528103]\n",
      " [0.7025561 ]\n",
      " [0.7457761 ]\n",
      " [0.82134914]\n",
      " [0.717525  ]\n",
      " [0.81333756]\n",
      " [0.453675  ]\n",
      " [0.43901956]\n",
      " [0.86825204]\n",
      " [0.7914897 ]\n",
      " [0.6110294 ]\n",
      " [0.3264647 ]\n",
      " [0.8657376 ]\n",
      " [0.8489752 ]\n",
      " [0.82410526]\n",
      " [0.6711731 ]\n",
      " [0.8899184 ]\n",
      " [0.88126683]\n",
      " [0.8112552 ]\n",
      " [0.44169462]\n",
      " [0.8707566 ]\n",
      " [0.8966588 ]\n",
      " [0.37041262]\n",
      " [0.17443931]\n",
      " [0.70766157]\n",
      " [0.47403333]\n",
      " [0.8627651 ]\n",
      " [0.31680486]\n",
      " [0.40966952]\n",
      " [0.47637904]\n",
      " [0.787442  ]\n",
      " [0.8499588 ]\n",
      " [0.1306884 ]\n",
      " [0.36893028]\n",
      " [0.70405453]\n",
      " [0.5126956 ]\n",
      " [0.51381135]\n",
      " [0.8049098 ]\n",
      " [0.18756181]\n",
      " [0.9167441 ]\n",
      " [0.17822069]\n",
      " [0.80776685]\n",
      " [0.7172853 ]\n",
      " [0.7347702 ]\n",
      " [0.80227405]\n",
      " [0.7346322 ]\n",
      " [0.89784145]] \n",
      "Correct(Y):\n",
      "  [[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] \n",
      "Accuracy:  0.77338606\n"
     ]
    }
   ],
   "source": [
    "# placeholders\n",
    "X = tf.placeholder(tf.float32, shape=[None, 8])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "# Variables\n",
    "W = tf.Variable(tf.random_normal([8, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# model\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "# cost function\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "\n",
    "# Minimize / train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "# Accuracy computaiton\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "# Launch the graph in a session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(10001):\n",
    "    cost_val, _ = sess.run([cost, train], feed_dict={X: x_data, Y: y_data})\n",
    "    \n",
    "    if step % 200 == 0:\n",
    "        print(step, cost_val)\n",
    "        \n",
    "# Accuracy Report\n",
    "h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X: x_data, Y: y_data})\n",
    "print(\"\\nHypothesis: \", h, \"\\nCorrect(Y):\\n \", c, \"\\nAccuracy: \", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "코스트는 1.1866201에서 0.48281896로 감소하고(코스트는 그다지 감소하지 않음) 정확도는 0.77"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예제 3. iris 데이터 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "idx = np.in1d(iris.target, [0, 2])  # 두 종만 사용\n",
    "X_data = iris.data[idx, :]\n",
    "y_data = (iris.target[idx] / 2)[:, np.newaxis]  # 0, 1로 만듦, 분석 shape를 맞추기 위해 차원 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 4), (100, 1))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.shape, y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.0718272\n",
      "200 0.2502231\n",
      "400 0.11173405\n",
      "600 0.07068116\n",
      "800 0.051516306\n",
      "1000 0.040495254\n",
      "1200 0.033354964\n",
      "1400 0.028358001\n",
      "1600 0.024667066\n",
      "1800 0.021830134\n",
      "2000 0.01958172\n",
      "2200 0.01775596\n",
      "2400 0.016243894\n",
      "2600 0.014971069\n",
      "2800 0.01388484\n",
      "3000 0.01294692\n",
      "3200 0.012128824\n",
      "3400 0.011408943\n",
      "3600 0.010770565\n",
      "3800 0.010200559\n",
      "4000 0.0096884845\n",
      "4200 0.009225921\n",
      "4400 0.008805979\n",
      "4600 0.008423042\n",
      "4800 0.008072387\n",
      "5000 0.007750106\n",
      "5200 0.007452875\n",
      "5400 0.007177868\n",
      "5600 0.006922666\n",
      "5800 0.0066852085\n",
      "6000 0.0064637195\n",
      "6200 0.0062566106\n",
      "6400 0.006062523\n",
      "6600 0.0058802734\n",
      "6800 0.005708794\n",
      "7000 0.0055471687\n",
      "7200 0.005394556\n",
      "7400 0.0052502197\n",
      "7600 0.0051135146\n",
      "7800 0.004983845\n",
      "8000 0.004860667\n",
      "8200 0.004743518\n",
      "8400 0.004631959\n",
      "8600 0.004525597\n",
      "8800 0.004424073\n",
      "9000 0.0043270676\n",
      "9200 0.004234283\n",
      "9400 0.004145438\n",
      "9600 0.004060305\n",
      "9800 0.003978648\n",
      "10000 0.0039002555\n",
      "\n",
      "Hypothesis:  [[2.3497343e-03]\n",
      " [4.9629211e-03]\n",
      " [3.8596392e-03]\n",
      " [8.9580119e-03]\n",
      " [2.4182200e-03]\n",
      " [2.9778481e-03]\n",
      " [5.1164329e-03]\n",
      " [4.0130317e-03]\n",
      " [1.0323793e-02]\n",
      " [5.8663785e-03]\n",
      " [1.7927885e-03]\n",
      " [7.0444345e-03]\n",
      " [5.3992271e-03]\n",
      " [4.0389299e-03]\n",
      " [3.1560659e-04]\n",
      " [6.6697598e-04]\n",
      " [8.6289644e-04]\n",
      " [2.4529099e-03]\n",
      " [2.1480918e-03]\n",
      " [2.4856925e-03]\n",
      " [4.4741333e-03]\n",
      " [2.8640032e-03]\n",
      " [1.1672676e-03]\n",
      " [8.2160532e-03]\n",
      " [1.7672926e-02]\n",
      " [8.0964863e-03]\n",
      " [5.9531331e-03]\n",
      " [2.8185546e-03]\n",
      " [2.2830963e-03]\n",
      " [9.7300708e-03]\n",
      " [9.4562173e-03]\n",
      " [2.6273429e-03]\n",
      " [1.4928877e-03]\n",
      " [7.0619583e-04]\n",
      " [6.1230659e-03]\n",
      " [1.9328296e-03]\n",
      " [1.0349154e-03]\n",
      " [2.6314855e-03]\n",
      " [6.8811178e-03]\n",
      " [3.5332739e-03]\n",
      " [2.0447075e-03]\n",
      " [1.2566239e-02]\n",
      " [5.6526065e-03]\n",
      " [5.8779716e-03]\n",
      " [8.9165568e-03]\n",
      " [5.8822036e-03]\n",
      " [3.2442808e-03]\n",
      " [5.9680939e-03]\n",
      " [2.0366907e-03]\n",
      " [3.2513142e-03]\n",
      " [9.9961913e-01]\n",
      " [9.9765992e-01]\n",
      " [9.9872667e-01]\n",
      " [9.9880242e-01]\n",
      " [9.9922699e-01]\n",
      " [9.9972463e-01]\n",
      " [9.9574697e-01]\n",
      " [9.9950957e-01]\n",
      " [9.9927694e-01]\n",
      " [9.9881399e-01]\n",
      " [9.9106705e-01]\n",
      " [9.9729204e-01]\n",
      " [9.9700379e-01]\n",
      " [9.9779266e-01]\n",
      " [9.9791652e-01]\n",
      " [9.9626553e-01]\n",
      " [9.9767458e-01]\n",
      " [9.9951506e-01]\n",
      " [9.9992371e-01]\n",
      " [9.9701715e-01]\n",
      " [9.9795079e-01]\n",
      " [9.9644023e-01]\n",
      " [9.9980342e-01]\n",
      " [9.9144661e-01]\n",
      " [9.9808991e-01]\n",
      " [9.9852860e-01]\n",
      " [9.8869884e-01]\n",
      " [9.9108922e-01]\n",
      " [9.9891675e-01]\n",
      " [9.9755555e-01]\n",
      " [9.9910128e-01]\n",
      " [9.9827152e-01]\n",
      " [9.9896228e-01]\n",
      " [9.9420536e-01]\n",
      " [9.9918079e-01]\n",
      " [9.9864781e-01]\n",
      " [9.9848360e-01]\n",
      " [9.9774051e-01]\n",
      " [9.8932523e-01]\n",
      " [9.9488527e-01]\n",
      " [9.9812198e-01]\n",
      " [9.8818034e-01]\n",
      " [9.9765992e-01]\n",
      " [9.9902916e-01]\n",
      " [9.9839187e-01]\n",
      " [9.9388456e-01]\n",
      " [9.9505299e-01]\n",
      " [9.9460644e-01]\n",
      " [9.9741203e-01]\n",
      " [9.9626946e-01]] \n",
      "Correct(Y):\n",
      "  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] \n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "# placeholders\n",
    "X = tf.placeholder(tf.float32, shape=[None, 4])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "# Variables\n",
    "W = tf.Variable(tf.random_normal([4, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# model\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "# cost function\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "# Accuracy computation\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "# Launch the graph in a session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(10001):\n",
    "    cost_val, _ = sess.run([cost, train], feed_dict={X: X_data, Y: y_data})\n",
    "    if step % 200 == 0:\n",
    "        print(step, cost_val)\n",
    "        \n",
    "h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X: X_data, Y: y_data})\n",
    "print(\"\\nHypothesis: \", h, \"\\nCorrect(Y):\\n \", c, \"\\nAccuracy: \", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "코스트 함수가 거의 제로로 수렴하였고, 정확도도 1.0임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
