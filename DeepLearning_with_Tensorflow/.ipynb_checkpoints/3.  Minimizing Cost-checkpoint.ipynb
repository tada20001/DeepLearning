{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.font_manager as fm\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "path = \"/Library/Fonts/NanumGothic.otf\"\n",
    "font_name = fm.FontProperties(fname=path, size=20).get_name()\n",
    "\n",
    "plt.rc('font', family=font_name)\n",
    "fm._rebuild()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cost를 최소화하자는 것은 cost를 최소화하는 w, b의 값을 찾는다는 의미다.\n",
    "\n",
    "### 1. simplified example (bias 생략)  : w값이 변할 때 cost 값이 어떻게 변하는지 살펴봄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [1, 2, 3]\n",
    "Y = [1, 2, 3]\n",
    "\n",
    "# 노드 정의 : 여기에서는 w 값을 세션 실행때 집어 넣기 위해서 placeholder로 설정 \n",
    "W = tf.placeholder(tf.float32)  \n",
    "\n",
    "# 모델 정의\n",
    "hypothesis = X * W\n",
    "\n",
    "# cost function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Launch the graph in a session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Initialize global variables in the graph\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 코스트 값 플롯팅을 위한 변수 설정\n",
    "W_val = []\n",
    "cost_val = []\n",
    "\n",
    "for i in range(-30, 50):\n",
    "    feed_W = i * 0.1  # W 값을 -3부터 5까지 20개로 나눠서 입력하여 코스트 함수 값을 찾아냄\n",
    "    curr_cost, curr_W = sess.run([cost, W], feed_dict={W : feed_W})\n",
    "    W_val.append(curr_W)\n",
    "    cost_val.append(curr_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting cost function\n",
    "plt.scatter(W_val, cost_val, c='red', s=50, marker='o', edgecolors='k')\n",
    "plt.xlabel('weight')\n",
    "plt.ylabel('cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Gradient descent\n",
    "위의 그래프에서 각 점에서 미분한 값(+ or -)에 따라 weight 값을 증가시킬지 감소시킬지 w 값을 조정하는 알고리즘"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "learning_rate = 0.1\n",
    "gradient = tf.reduce_mean((W * X - Y) * X)  # bias 가 없을 경우\n",
    "descent = W - learning_rate * gradient\n",
    "W = tf.assign(descent)  # update된 weight 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/imjunghee/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "0 3.0922003 [0.18598878]\n",
      "1 0.87955886 [0.56586075]\n",
      "2 0.25018558 [0.7684591]\n",
      "3 0.071163915 [0.8765115]\n",
      "4 0.020242164 [0.9341395]\n",
      "5 0.0057577654 [0.9648744]\n",
      "6 0.001637768 [0.9812663]\n",
      "7 0.0004658563 [0.9900087]\n",
      "8 0.00013250798 [0.99467134]\n",
      "9 3.769116e-05 [0.99715805]\n",
      "10 1.0720941e-05 [0.9984843]\n",
      "11 3.0495933e-06 [0.99919164]\n",
      "12 8.674204e-07 [0.9995689]\n",
      "13 2.468243e-07 [0.99977005]\n",
      "14 7.016589e-08 [0.9998774]\n",
      "15 1.995951e-08 [0.9999346]\n",
      "16 5.6780194e-09 [0.99996513]\n",
      "17 1.6138983e-09 [0.9999814]\n",
      "18 4.5450577e-10 [0.9999901]\n",
      "19 1.3195844e-10 [0.9999947]\n",
      "20 3.629097e-11 [0.9999972]\n"
     ]
    }
   ],
   "source": [
    "# 전체 코드\n",
    "x_data = [1, 2, 3]\n",
    "y_data = [1, 2, 3]\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "hypothesis = W * X\n",
    "\n",
    "# cost function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# minimize : Gradient Descent using derivative W -= learning_rate * derivative\n",
    "learning_rate = 0.1\n",
    "gradient = tf.reduce_mean((W * X - Y) * X)  # 미분 연산\n",
    "descent = W - learning_rate * gradient\n",
    "update = W.assign(descent)\n",
    "\n",
    "# 위와 동일한 코드\n",
    "#optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "#train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a Session\n",
    "sess = tf.Session()\n",
    "# Initialize global variables in the graph\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(21):\n",
    "    sess.run(update, feed_dict={X: x_data, Y: y_data})\n",
    "    print(step, sess.run(cost, feed_dict={X: x_data, Y: y_data}), sess.run(W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 20에 도달하면, cost 값은 거의 0에 수렴되고, weight는 1에 수렴된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 크게 벗어난 weight 값을 초기에 설정했을 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5.0\n",
      "1 1.2666664\n",
      "2 1.0177778\n",
      "3 1.0011852\n",
      "4 1.000079\n",
      "5 1.0000052\n",
      "6 1.0000004\n",
      "7 1.0\n",
      "8 1.0\n",
      "9 1.0\n",
      "10 1.0\n",
      "11 1.0\n",
      "12 1.0\n",
      "13 1.0\n",
      "14 1.0\n",
      "15 1.0\n",
      "16 1.0\n",
      "17 1.0\n",
      "18 1.0\n",
      "19 1.0\n",
      "20 1.0\n",
      "21 1.0\n",
      "22 1.0\n",
      "23 1.0\n",
      "24 1.0\n",
      "25 1.0\n",
      "26 1.0\n",
      "27 1.0\n",
      "28 1.0\n",
      "29 1.0\n",
      "30 1.0\n",
      "31 1.0\n",
      "32 1.0\n",
      "33 1.0\n",
      "34 1.0\n",
      "35 1.0\n",
      "36 1.0\n",
      "37 1.0\n",
      "38 1.0\n",
      "39 1.0\n",
      "40 1.0\n",
      "41 1.0\n",
      "42 1.0\n",
      "43 1.0\n",
      "44 1.0\n",
      "45 1.0\n",
      "46 1.0\n",
      "47 1.0\n",
      "48 1.0\n",
      "49 1.0\n",
      "50 1.0\n",
      "51 1.0\n",
      "52 1.0\n",
      "53 1.0\n",
      "54 1.0\n",
      "55 1.0\n",
      "56 1.0\n",
      "57 1.0\n",
      "58 1.0\n",
      "59 1.0\n",
      "60 1.0\n",
      "61 1.0\n",
      "62 1.0\n",
      "63 1.0\n",
      "64 1.0\n",
      "65 1.0\n",
      "66 1.0\n",
      "67 1.0\n",
      "68 1.0\n",
      "69 1.0\n",
      "70 1.0\n",
      "71 1.0\n",
      "72 1.0\n",
      "73 1.0\n",
      "74 1.0\n",
      "75 1.0\n",
      "76 1.0\n",
      "77 1.0\n",
      "78 1.0\n",
      "79 1.0\n",
      "80 1.0\n",
      "81 1.0\n",
      "82 1.0\n",
      "83 1.0\n",
      "84 1.0\n",
      "85 1.0\n",
      "86 1.0\n",
      "87 1.0\n",
      "88 1.0\n",
      "89 1.0\n",
      "90 1.0\n",
      "91 1.0\n",
      "92 1.0\n",
      "93 1.0\n",
      "94 1.0\n",
      "95 1.0\n",
      "96 1.0\n",
      "97 1.0\n",
      "98 1.0\n",
      "99 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# tf Graph Input\n",
    "X = [1, 2, 3]\n",
    "Y = [1, 2, 3]\n",
    "\n",
    "# set the wrong model weight\n",
    "W = tf.Variable(5.0)\n",
    "\n",
    "# linear model\n",
    "hypothesis = X * W\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# minimize and train\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(100):\n",
    "    print(step, sess.run(W))\n",
    "    sess.run(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "초기값 w 를 5.0으로 설정하더라도 6번째 단계에서 이미 weight 값이 1로 수렴된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -3.0\n",
      "1 0.7333336\n",
      "2 0.98222226\n",
      "3 0.9988148\n",
      "4 0.99992096\n",
      "5 0.9999947\n",
      "6 0.99999964\n",
      "7 0.99999994\n",
      "8 1.0\n",
      "9 1.0\n",
      "10 1.0\n",
      "11 1.0\n",
      "12 1.0\n",
      "13 1.0\n",
      "14 1.0\n",
      "15 1.0\n",
      "16 1.0\n",
      "17 1.0\n",
      "18 1.0\n",
      "19 1.0\n",
      "20 1.0\n",
      "21 1.0\n",
      "22 1.0\n",
      "23 1.0\n",
      "24 1.0\n",
      "25 1.0\n",
      "26 1.0\n",
      "27 1.0\n",
      "28 1.0\n",
      "29 1.0\n",
      "30 1.0\n",
      "31 1.0\n",
      "32 1.0\n",
      "33 1.0\n",
      "34 1.0\n",
      "35 1.0\n",
      "36 1.0\n",
      "37 1.0\n",
      "38 1.0\n",
      "39 1.0\n",
      "40 1.0\n",
      "41 1.0\n",
      "42 1.0\n",
      "43 1.0\n",
      "44 1.0\n",
      "45 1.0\n",
      "46 1.0\n",
      "47 1.0\n",
      "48 1.0\n",
      "49 1.0\n",
      "50 1.0\n",
      "51 1.0\n",
      "52 1.0\n",
      "53 1.0\n",
      "54 1.0\n",
      "55 1.0\n",
      "56 1.0\n",
      "57 1.0\n",
      "58 1.0\n",
      "59 1.0\n",
      "60 1.0\n",
      "61 1.0\n",
      "62 1.0\n",
      "63 1.0\n",
      "64 1.0\n",
      "65 1.0\n",
      "66 1.0\n",
      "67 1.0\n",
      "68 1.0\n",
      "69 1.0\n",
      "70 1.0\n",
      "71 1.0\n",
      "72 1.0\n",
      "73 1.0\n",
      "74 1.0\n",
      "75 1.0\n",
      "76 1.0\n",
      "77 1.0\n",
      "78 1.0\n",
      "79 1.0\n",
      "80 1.0\n",
      "81 1.0\n",
      "82 1.0\n",
      "83 1.0\n",
      "84 1.0\n",
      "85 1.0\n",
      "86 1.0\n",
      "87 1.0\n",
      "88 1.0\n",
      "89 1.0\n",
      "90 1.0\n",
      "91 1.0\n",
      "92 1.0\n",
      "93 1.0\n",
      "94 1.0\n",
      "95 1.0\n",
      "96 1.0\n",
      "97 1.0\n",
      "98 1.0\n",
      "99 1.0\n"
     ]
    }
   ],
   "source": [
    "# W 초기값을 -3으로 줄 경우\n",
    "\n",
    "# tf Graph Input\n",
    "X = [1, 2, 3]\n",
    "Y = [1, 2, 3]\n",
    "\n",
    "# set the wrong model weight\n",
    "W = tf.Variable(-3.0)\n",
    "\n",
    "# linear model\n",
    "hypothesis = X * W\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# minimize and train\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(100):\n",
    "    print(step, sess.run(W))\n",
    "    sess.run(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 경우에도 8단계에서 1로 수렴된다.\n",
    "\n",
    "### 자동으로 계산한 미분값과 수동으로 계산한 값 비교 : compute_gradients( ) and appy_gradients( ) 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [37.333332, 5.0, [(37.333336, 5.0)]]\n",
      "1 [33.84889, 4.6266665, [(33.84889, 4.6266665)]]\n",
      "2 [30.689657, 4.2881775, [(30.689657, 4.2881775)]]\n",
      "3 [27.825287, 3.9812808, [(27.825287, 3.9812808)]]\n",
      "4 [25.228262, 3.703028, [(25.228262, 3.703028)]]\n",
      "5 [22.873621, 3.4507453, [(22.873623, 3.4507453)]]\n",
      "6 [20.738752, 3.2220092, [(20.73875, 3.2220092)]]\n",
      "7 [18.803137, 3.0146217, [(18.803137, 3.0146217)]]\n",
      "8 [17.048176, 2.8265903, [(17.048176, 2.8265903)]]\n",
      "9 [15.457013, 2.6561086, [(15.457014, 2.6561086)]]\n",
      "10 [14.014359, 2.5015385, [(14.01436, 2.5015385)]]\n",
      "11 [12.706352, 2.361395, [(12.706352, 2.361395)]]\n",
      "12 [11.520427, 2.2343314, [(11.520427, 2.2343314)]]\n",
      "13 [10.445186, 2.119127, [(10.445185, 2.119127)]]\n",
      "14 [9.470302, 2.0146751, [(9.470302, 2.0146751)]]\n",
      "15 [8.586407, 1.9199722, [(8.586407, 1.9199722)]]\n",
      "16 [7.785009, 1.8341081, [(7.785009, 1.8341081)]]\n",
      "17 [7.0584083, 1.756258, [(7.0584083, 1.756258)]]\n",
      "18 [6.399624, 1.685674, [(6.399624, 1.685674)]]\n",
      "19 [5.8023257, 1.6216778, [(5.8023252, 1.6216778)]]\n",
      "20 [5.260776, 1.5636545, [(5.260776, 1.5636545)]]\n",
      "21 [4.7697697, 1.5110468, [(4.7697697, 1.5110468)]]\n",
      "22 [4.324591, 1.4633491, [(4.324591, 1.4633491)]]\n",
      "23 [3.9209633, 1.4201032, [(3.9209635, 1.4201032)]]\n",
      "24 [3.5550067, 1.3808936, [(3.5550067, 1.3808936)]]\n",
      "25 [3.2232056, 1.3453435, [(3.2232056, 1.3453435)]]\n",
      "26 [2.9223735, 1.3131114, [(2.9223735, 1.3131114)]]\n",
      "27 [2.6496189, 1.2838877, [(2.6496186, 1.2838877)]]\n",
      "28 [2.4023216, 1.2573916, [(2.4023216, 1.2573916)]]\n",
      "29 [2.178105, 1.2333684, [(2.178105, 1.2333684)]]\n",
      "30 [1.9748148, 1.2115873, [(1.9748147, 1.2115873)]]\n",
      "31 [1.7904993, 1.1918392, [(1.7904994, 1.1918392)]]\n",
      "32 [1.623386, 1.1739342, [(1.6233861, 1.1739342)]]\n",
      "33 [1.4718695, 1.1577003, [(1.4718695, 1.1577003)]]\n",
      "34 [1.3344955, 1.1429816, [(1.3344957, 1.1429816)]]\n",
      "35 [1.2099417, 1.1296366, [(1.2099419, 1.1296366)]]\n",
      "36 [1.0970144, 1.1175373, [(1.0970144, 1.1175373)]]\n",
      "37 [0.9946267, 1.1065671, [(0.9946267, 1.1065671)]]\n",
      "38 [0.90179497, 1.0966209, [(0.901795, 1.0966209)]]\n",
      "39 [0.8176275, 1.087603, [(0.81762755, 1.087603)]]\n",
      "40 [0.7413151, 1.0794266, [(0.7413151, 1.0794266)]]\n",
      "41 [0.67212623, 1.0720135, [(0.67212623, 1.0720135)]]\n",
      "42 [0.609394, 1.0652922, [(0.609394, 1.0652922)]]\n",
      "43 [0.5525169, 1.0591983, [(0.5525169, 1.0591983)]]\n",
      "44 [0.50094914, 1.0536731, [(0.50094914, 1.0536731)]]\n",
      "45 [0.45419374, 1.0486636, [(0.45419377, 1.0486636)]]\n",
      "46 [0.41180158, 1.0441216, [(0.41180158, 1.0441216)]]\n",
      "47 [0.37336722, 1.0400037, [(0.37336725, 1.0400037)]]\n",
      "48 [0.33851996, 1.03627, [(0.33852, 1.03627)]]\n",
      "49 [0.30692515, 1.0328848, [(0.30692515, 1.0328848)]]\n",
      "50 [0.27827826, 1.0298156, [(0.2782783, 1.0298156)]]\n",
      "51 [0.25230527, 1.0270327, [(0.25230527, 1.0270327)]]\n",
      "52 [0.2287569, 1.0245097, [(0.2287569, 1.0245097)]]\n",
      "53 [0.20740573, 1.022222, [(0.20740573, 1.022222)]]\n",
      "54 [0.18804836, 1.020148, [(0.18804836, 1.020148)]]\n",
      "55 [0.17049654, 1.0182675, [(0.17049655, 1.0182675)]]\n",
      "56 [0.15458433, 1.0165626, [(0.15458433, 1.0165626)]]\n",
      "57 [0.14015675, 1.0150168, [(0.14015675, 1.0150168)]]\n",
      "58 [0.12707591, 1.0136153, [(0.12707591, 1.0136153)]]\n",
      "59 [0.11521538, 1.0123445, [(0.11521538, 1.0123445)]]\n",
      "60 [0.10446167, 1.0111923, [(0.10446167, 1.0111923)]]\n",
      "61 [0.09471202, 1.0101477, [(0.09471202, 1.0101477)]]\n",
      "62 [0.08587202, 1.0092006, [(0.08587202, 1.0092006)]]\n",
      "63 [0.07785805, 1.0083419, [(0.07785805, 1.0083419)]]\n",
      "64 [0.07059129, 1.0075634, [(0.07059129, 1.0075634)]]\n",
      "65 [0.06400236, 1.0068574, [(0.06400236, 1.0068574)]]\n",
      "66 [0.05802846, 1.0062174, [(0.05802846, 1.0062174)]]\n",
      "67 [0.052612226, 1.005637, [(0.052612226, 1.005637)]]\n",
      "68 [0.047702473, 1.005111, [(0.047702473, 1.005111)]]\n",
      "69 [0.043249767, 1.0046339, [(0.043249767, 1.0046339)]]\n",
      "70 [0.03921318, 1.0042014, [(0.03921318, 1.0042014)]]\n",
      "71 [0.035553534, 1.0038093, [(0.035553537, 1.0038093)]]\n",
      "72 [0.032236177, 1.0034539, [(0.03223618, 1.0034539)]]\n",
      "73 [0.029227654, 1.0031315, [(0.029227655, 1.0031315)]]\n",
      "74 [0.02649951, 1.0028392, [(0.02649951, 1.0028392)]]\n",
      "75 [0.024025917, 1.0025742, [(0.024025917, 1.0025742)]]\n",
      "76 [0.021783749, 1.002334, [(0.02178375, 1.002334)]]\n",
      "77 [0.01975123, 1.0021162, [(0.019751232, 1.0021162)]]\n",
      "78 [0.017907381, 1.0019187, [(0.017907381, 1.0019187)]]\n",
      "79 [0.016236702, 1.0017396, [(0.016236704, 1.0017396)]]\n",
      "80 [0.014720838, 1.0015773, [(0.014720838, 1.0015773)]]\n",
      "81 [0.01334699, 1.00143, [(0.013346991, 1.00143)]]\n",
      "82 [0.012100856, 1.0012965, [(0.012100856, 1.0012965)]]\n",
      "83 [0.010971785, 1.0011755, [(0.010971785, 1.0011755)]]\n",
      "84 [0.0099481745, 1.0010659, [(0.0099481745, 1.0010659)]]\n",
      "85 [0.009018898, 1.0009663, [(0.009018898, 1.0009663)]]\n",
      "86 [0.008176883, 1.0008761, [(0.008176884, 1.0008761)]]\n",
      "87 [0.007413149, 1.0007943, [(0.007413149, 1.0007943)]]\n",
      "88 [0.006721576, 1.0007201, [(0.006721576, 1.0007201)]]\n",
      "89 [0.0060940585, 1.0006529, [(0.0060940585, 1.0006529)]]\n",
      "90 [0.005525271, 1.000592, [(0.0055252714, 1.000592)]]\n",
      "91 [0.0050098896, 1.0005368, [(0.0050098896, 1.0005368)]]\n",
      "92 [0.004542589, 1.0004867, [(0.004542589, 1.0004867)]]\n",
      "93 [0.0041189194, 1.0004413, [(0.0041189194, 1.0004413)]]\n",
      "94 [0.0037339528, 1.0004001, [(0.003733953, 1.0004001)]]\n",
      "95 [0.0033854644, 1.0003628, [(0.0033854644, 1.0003628)]]\n",
      "96 [0.0030694802, 1.0003289, [(0.0030694804, 1.0003289)]]\n",
      "97 [0.0027837753, 1.0002983, [(0.0027837753, 1.0002983)]]\n",
      "98 [0.0025234222, 1.0002704, [(0.0025234222, 1.0002704)]]\n",
      "99 [0.0022875469, 1.0002451, [(0.0022875469, 1.0002451)]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "X = [1, 2, 3]\n",
    "Y = [1, 2, 3]\n",
    "\n",
    "# Set the wrong model weight\n",
    "W = tf.Variable(5.)\n",
    "\n",
    "# Linear Model\n",
    "hypothesis = X * W\n",
    "\n",
    "# Manual gradient\n",
    "gradient = tf.reduce_mean((W * X - Y) * X) * 2  # 그레디언트를 출력하기 위해 연산 정의\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "\n",
    "# Get gradients : 최소화를 바로 하지 않고 cost에 맞는 gradient를 계산하는데 이때 나온 것을 임의로 조정 가능. 만약 수정한다면 이 값을 아래에 적용\n",
    "gvs = optimizer.compute_gradients(cost, [W])  # 미분 대상 weight 설정 필요\n",
    "\n",
    "# apply gradients  ==> training\n",
    "apply_gradients = optimizer.apply_gradients(gvs) \n",
    "\n",
    "# Launch the graph in a session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(100):\n",
    "    print(step, sess.run([gradient, W, gvs]))\n",
    "    sess.run(apply_gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "수동으로 계산한 미분 값 gradient와 자동으로 계산한 미분 값 gvs 값이 동일하다는 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
