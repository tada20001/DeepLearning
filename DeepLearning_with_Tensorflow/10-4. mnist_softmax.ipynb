{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax classifier for MNIST + using GradientDescentOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001, Cost: 13.149737597\n",
      "Epoch: 0002, Cost: 11.190150826\n",
      "Epoch: 0003, Cost: 9.905000720\n",
      "Epoch: 0004, Cost: 8.963398793\n",
      "Epoch: 0005, Cost: 8.227733525\n",
      "Epoch: 0006, Cost: 7.630932511\n",
      "Epoch: 0007, Cost: 7.129129060\n",
      "Epoch: 0008, Cost: 6.692301192\n",
      "Epoch: 0009, Cost: 6.302305709\n",
      "Epoch: 0010, Cost: 5.949759123\n",
      "Epoch: 0011, Cost: 5.629493310\n",
      "Epoch: 0012, Cost: 5.338033149\n",
      "Epoch: 0013, Cost: 5.072678408\n",
      "Epoch: 0014, Cost: 4.830986723\n",
      "Epoch: 0015, Cost: 4.610720544\n",
      "Epoch: 0016, Cost: 4.409739172\n",
      "Epoch: 0017, Cost: 4.226170599\n",
      "Epoch: 0018, Cost: 4.058246940\n",
      "Epoch: 0019, Cost: 3.904394428\n",
      "Epoch: 0020, Cost: 3.763198183\n",
      "Epoch: 0021, Cost: 3.633403289\n",
      "Epoch: 0022, Cost: 3.513856945\n",
      "Epoch: 0023, Cost: 3.403523572\n",
      "Epoch: 0024, Cost: 3.301440805\n",
      "Epoch: 0025, Cost: 3.206807643\n",
      "Epoch: 0026, Cost: 3.118896566\n",
      "Epoch: 0027, Cost: 3.037045508\n",
      "Epoch: 0028, Cost: 2.960672492\n",
      "Epoch: 0029, Cost: 2.889265863\n",
      "Epoch: 0030, Cost: 2.822372587\n",
      "Epoch: 0031, Cost: 2.759554753\n",
      "Epoch: 0032, Cost: 2.700484065\n",
      "Epoch: 0033, Cost: 2.644821522\n",
      "Epoch: 0034, Cost: 2.592283032\n",
      "Epoch: 0035, Cost: 2.542606443\n",
      "Epoch: 0036, Cost: 2.495562519\n",
      "Epoch: 0037, Cost: 2.450953084\n",
      "Epoch: 0038, Cost: 2.408595072\n",
      "Epoch: 0039, Cost: 2.368304020\n",
      "Epoch: 0040, Cost: 2.329936244\n",
      "Epoch: 0041, Cost: 2.293366310\n",
      "Epoch: 0042, Cost: 2.258445211\n",
      "Epoch: 0043, Cost: 2.225059872\n",
      "Epoch: 0044, Cost: 2.193133960\n",
      "Epoch: 0045, Cost: 2.162557591\n",
      "Epoch: 0046, Cost: 2.133226288\n",
      "Epoch: 0047, Cost: 2.105095515\n",
      "Epoch: 0048, Cost: 2.078055350\n",
      "Epoch: 0049, Cost: 2.052063300\n",
      "Epoch: 0050, Cost: 2.027049086\n",
      "Learning Finished!\n",
      "Accuracy: 0.6512\n",
      "Label: [4]\n",
      "Prediction: [9]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.random.set_random_seed(777)\n",
    "nb_classes = 10\n",
    "\n",
    "# input placeholders\n",
    "X = tf.placeholder(tf.float32, shape=[None, 28*28])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, nb_classes])\n",
    "\n",
    "# weights & bias for nn layers\n",
    "W = tf.Variable(tf.random_normal([28 * 28, nb_classes]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([nb_classes]), name='bias')\n",
    "\n",
    "# hypothesis\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# parameters\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "num_epochs = 50\n",
    "num_iterations = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "# define cost function : sigmoid + cost ==> softmax\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=hypothesis, labels=tf.stop_gradient(Y)))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# compute accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, axis=1), tf.argmax(Y, axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, dtype=tf.float32))\n",
    "\n",
    "# training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        avg_cost = 0\n",
    "        \n",
    "        for i in range(num_iterations):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            _, cost_val = sess.run([train, cost], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "            avg_cost += cost_val / num_iterations\n",
    "            \n",
    "        print(f\"Epoch: {(epoch + 1):04d}, Cost: {avg_cost:.9f}\")\n",
    "        \n",
    "    print(\"Learning Finished!\")\n",
    "\n",
    "    # Test model and check accuracy\n",
    "    print(\"Accuracy:\", sess.run(accuracy, feed_dict={X: mnist.test.images, Y:mnist.test.labels}))\n",
    "    \n",
    "    \n",
    "    # get one and predict\n",
    "    import numpy as np\n",
    "    idx = np.random.choice(mnist.test.num_examples, 1)[0]\n",
    "    print(\"Label:\", sess.run(tf.argmax(mnist.test.labels[idx:idx+1], axis=1)))\n",
    "    print(\"Prediction:\", sess.run(tf.argmax(hypothesis, axis=1), feed_dict={X: mnist.test.images[idx: idx+1]}))\n",
    "    \n",
    "    import matplotlib.pylab as plt\n",
    "    plt.imshow(mnist.test.images[idx:idx+1].reshape(28, 28), cmap=\"Greys\", interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax classifier for MNIST + using AdamOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 0001, Cost: 4.531042674\n",
      "Epoch: 0002, Cost: 1.561328321\n",
      "Epoch: 0003, Cost: 1.071527543\n",
      "Epoch: 0004, Cost: 0.861932872\n",
      "Epoch: 0005, Cost: 0.741294320\n",
      "Epoch: 0006, Cost: 0.662219081\n",
      "Epoch: 0007, Cost: 0.605246459\n",
      "Epoch: 0008, Cost: 0.562254292\n",
      "Epoch: 0009, Cost: 0.527866924\n",
      "Epoch: 0010, Cost: 0.500497394\n",
      "Epoch: 0011, Cost: 0.477142519\n",
      "Epoch: 0012, Cost: 0.457676141\n",
      "Epoch: 0013, Cost: 0.440929115\n",
      "Epoch: 0014, Cost: 0.425966441\n",
      "Epoch: 0015, Cost: 0.413433797\n",
      "Epoch: 0016, Cost: 0.401521268\n",
      "Epoch: 0017, Cost: 0.392043293\n",
      "Epoch: 0018, Cost: 0.382284101\n",
      "Epoch: 0019, Cost: 0.374197577\n",
      "Epoch: 0020, Cost: 0.366788798\n",
      "Epoch: 0021, Cost: 0.359882501\n",
      "Epoch: 0022, Cost: 0.353549796\n",
      "Epoch: 0023, Cost: 0.347388411\n",
      "Epoch: 0024, Cost: 0.342204496\n",
      "Epoch: 0025, Cost: 0.336634896\n",
      "Epoch: 0026, Cost: 0.332245425\n",
      "Epoch: 0027, Cost: 0.328171529\n",
      "Epoch: 0028, Cost: 0.323839797\n",
      "Epoch: 0029, Cost: 0.319635935\n",
      "Epoch: 0030, Cost: 0.316136286\n",
      "Epoch: 0031, Cost: 0.312635265\n",
      "Epoch: 0032, Cost: 0.309740317\n",
      "Epoch: 0033, Cost: 0.306373986\n",
      "Epoch: 0034, Cost: 0.303441450\n",
      "Epoch: 0035, Cost: 0.300817971\n",
      "Epoch: 0036, Cost: 0.298039776\n",
      "Epoch: 0037, Cost: 0.295622880\n",
      "Epoch: 0038, Cost: 0.293350093\n",
      "Epoch: 0039, Cost: 0.290680319\n",
      "Epoch: 0040, Cost: 0.289141292\n",
      "Epoch: 0041, Cost: 0.287068001\n",
      "Epoch: 0042, Cost: 0.284919532\n",
      "Epoch: 0043, Cost: 0.283302680\n",
      "Epoch: 0044, Cost: 0.281295624\n",
      "Epoch: 0045, Cost: 0.279800673\n",
      "Epoch: 0046, Cost: 0.277851198\n",
      "Epoch: 0047, Cost: 0.276649549\n",
      "Epoch: 0048, Cost: 0.274658777\n",
      "Epoch: 0049, Cost: 0.273581606\n",
      "Epoch: 0050, Cost: 0.271777534\n",
      "Learning Finished!\n",
      "Accuracy: 0.9197\n",
      "Label:  [3]\n",
      "Prediction:  [3]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAN6klEQVR4nO3df6xU9ZnH8c+z/PiH1gSWy5XYq3Qb/lizurQZCQFjapqt/Ei8NloFTUWDe2uCCcUmrnFN6h+SmI21IWZTQ4X0du3aNCkIf2DtlTQx1UgYkQoWXdkbllJvuEPE9BIxLPDsH/ewucKc71xmzswZeN6v5GZmzjPfe56cy4czc86Z+Zq7C8CV72/KbgBAZxB2IAjCDgRB2IEgCDsQxNROrmz27Nk+b968Tq4SCOXw4cM6fvy41au1FHYzWyppo6Qpkl5092dSz583b56q1WorqwSQUKlUcmtNv4w3symS/l3SMknXS1plZtc3+/sAtFcr79kXSjrk7sPuflrSryT1F9MWgKK1EvZrJP15wuOj2bIvMLMBM6uaWbVWq7WwOgCtaCXs9Q4CXHTtrbtvcveKu1d6enpaWB2AVrQS9qOS+iY8/oqkj1trB0C7tBL2PZLmm9lXzWy6pJWSdhTTFoCiNX3qzd3PmNkjkl7T+Km3Le7+fmGdAShUS+fZ3X2npJ0F9QKgjbhcFgiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSBamsUVxdizZ0+yvmjRomR9ypQpubX7778/Ofaee+5J1m+55ZZkferU9D+hVG/orJbCbmaHJY1JOivpjLtXimgKQPGK2LPf6u7HC/g9ANqI9+xAEK2G3SX9zszeMbOBek8wswEzq5pZtVartbg6AM1qNexL3P0bkpZJWmtmFx3NcfdN7l5x90pPT0+LqwPQrJbC7u4fZ7ejkrZJWlhEUwCK13TYzWyGmX35/H1J35Z0oKjGABSrlaPxvZK2mdn53/Of7v7bQroK5tSpU8l6X19fsn7kyJHc2pYtW5JjN2/enKxnf99cK1asSNbXrFmTW+vv729p3bg0TYfd3Ycl/WOBvQBoI069AUEQdiAIwg4EQdiBIAg7EIS5e8dWVqlUvFqtdmx9V4pGf6M333wzt7Zhw4bk2HfffTdZHx0dTdZb8corryTrt99+e9vWfaWqVCqqVqt1z1myZweCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIPgq6ctAo4963nzzzbm1V199NTn2xIkTyfru3buT9XvvvTdZ//TTT3Nrr7/+enIs59mLxZ4dCIKwA0EQdiAIwg4EQdiBIAg7EARhB4LgPHtwM2fOTNZvvPHGZH1sbKzpdS9durTpsbh07NmBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjOswd38uTJZH316tXJ+tmzZ5P19evX59aWLVuWHItiNdyzm9kWMxs1swMTls0ysyEz+yi7TV+ZAaB0k3kZ/3NJF17q9LikXe4+X9Ku7DGALtYw7O7+hqRPLljcL2kwuz8o6Y6C+wJQsGYP0PW6+4gkZbdz8p5oZgNmVjWzaq1Wa3J1AFrV9qPx7r7J3SvuXunp6Wn36gDkaDbsx8xsriRlt+2b6hNAIZoN+w5J58/JrJa0vZh2ALRLw/PsZvaypG9Kmm1mRyX9SNIzkn5tZmskHZH03XY2ieadPn06WX/wwQeT9V27diXrN910U7L+5JNP5tYafR8+itUw7O6+Kqf0rYJ7AdBGXC4LBEHYgSAIOxAEYQeCIOxAEHzE9Qrw+eef59buu+++5NitW7cm61dffXWyvmPHjmS90VdVo3PYswNBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEJxnvwwMDw8n64sXL86tjY6mv1fkuuuuS9Zfe+21ZL23tzdZR/dgzw4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQXCevQs8+uijyfrGjRuT9XPnzuXW5szJnZlLkrR3795kfdasWck6Lh/s2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCM6zd4H9+/cn6+6erKemPq7VasmxixYtStbXrVuXrD/wwAPJ+owZM5J1dE7DPbuZbTGzUTM7MGHZU2b2FzPbl/0sb2+bAFo1mZfxP5e0tM7yn7j7guxnZ7FtAShaw7C7+xuSPulALwDaqJUDdI+Y2XvZy/zcCb3MbMDMqmZWbfT+EUD7NBv2n0r6mqQFkkYk/Tjvie6+yd0r7l7p6elpcnUAWtVU2N39mLufdfdzkn4maWGxbQEoWlNhN7O5Ex5+R9KBvOcC6A42iXO4L0v6pqTZko5J+lH2eIEkl3RY0vfdfaTRyiqViler1ZYavhKdOXMmWf/ss8+S9aGhodzaBx98kBz70ksvJesffvhhst5o/vWnn346t/bwww8nx6auH0B9lUpF1Wq17oZreFGNu6+qs3hzy10B6CgulwWCIOxAEIQdCIKwA0EQdiAIPuLaBaZOTf8ZrrrqqmT9zjvvbHrd69evT9a3b9+erD/00EPJ+tq1a3Nrqa/AbjQWl449OxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4E0fAjrkXiI65XnkZfg3333Xfn1g4dOpQcOzw8nKz39fUl6xGlPuLKnh0IgrADQRB2IAjCDgRB2IEgCDsQBGEHguDz7GjJDTfckKw/99xzubUVK1Ykx77wwgvJ+oYNG5J1fBF7diAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgvPsaKs5c+Y0PXbnzp3JOufZL03DPbuZ9ZnZ783soJm9b2brsuWzzGzIzD7KbtMTdQMo1WRexp+R9EN3/3tJiyStNbPrJT0uaZe7z5e0K3sMoEs1DLu7j7j73uz+mKSDkq6R1C9pMHvaoKQ72tUkgNZd0gE6M5sn6euSdkvqdfcRafw/BEl135yZ2YCZVc2sWqvVWusWQNMmHXYz+5Kk30j6gbv/dbLj3H2Tu1fcvdLT09NMjwAKMKmwm9k0jQf9l+6+NVt8zMzmZvW5kkbb0yKAIjQ89WZmJmmzpIPuPvHzijskrZb0THabntsXTRsYGEjWn3322dxao+me2+3kyZNNj128eHGBnWAy59mXSPqepP1mti9b9oTGQ/5rM1sj6Yik77anRQBFaBh2d/+DpLpfOi/pW8W2A6BduFwWCIKwA0EQdiAIwg4EQdiBIPiI62VgbGwsWZ8/f35u7cUXX0yOve2225L1U6dOJetvv/12sr5y5crc2vglHPnuuuuuZB2Xhj07EARhB4Ig7EAQhB0IgrADQRB2IAjCDgTBefbLwODgYLK+ZMmS3Fp/f39ybKNvD2p0nr2Vz6s///zzyfqtt97a9O/GxdizA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQnGe/DEyfPj1Zf+utt3JrQ0NDybHbtm1L1k+cOJGsX3vttcn6Y489llvr7e1NjkWx2LMDQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCTmZ+9T9IvJF0t6ZykTe6+0cyekvTPkmrZU59w953tahT5pk2blltbvnx5cmyjOq4ck7mo5oykH7r7XjP7sqR3zOz8lRo/cfdn29cegKJMZn72EUkj2f0xMzso6Zp2NwagWJf0nt3M5kn6uqTd2aJHzOw9M9tiZjNzxgyYWdXMqrVard5TAHTApMNuZl+S9BtJP3D3v0r6qaSvSVqg8T3/j+uNc/dN7l5x90qj7zsD0D6TCruZTdN40H/p7lslyd2PuftZdz8n6WeSFravTQCtahh2G59qc7Okg+7+3ITlcyc87TuSDhTfHoCiTOZo/BJJ35O038z2ZcuekLTKzBZIckmHJX2/LR0CKMRkjsb/QVK9ibQ5pw5cRriCDgiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EIS5e+dWZlaT9D8TFs2WdLxjDVyabu2tW/uS6K1ZRfZ2nbvX/f63job9opWbVd29UloDCd3aW7f2JdFbszrVGy/jgSAIOxBE2WHfVPL6U7q1t27tS6K3ZnWkt1LfswPonLL37AA6hLADQZQSdjNbamYfmtkhM3u8jB7ymNlhM9tvZvvMrFpyL1vMbNTMDkxYNsvMhszso+y27hx7JfX2lJn9Jdt2+8yslPmgzazPzH5vZgfN7H0zW5ctL3XbJfrqyHbr+Ht2M5si6b8k/ZOko5L2SFrl7n/qaCM5zOywpIq7l34BhpndIumkpF+4+z9ky/5N0ifu/kz2H+VMd/+XLuntKUkny57GO5utaO7EacYl3SHpAZW47RJ93a0ObLcy9uwLJR1y92F3Py3pV5L6S+ij67n7G5I+uWBxv6TB7P6gxv+xdFxOb13B3UfcfW92f0zS+WnGS912ib46ooywXyPpzxMeH1V3zffukn5nZu+Y2UDZzdTR6+4j0vg/HklzSu7nQg2n8e6kC6YZ75pt18z0560qI+z1ppLqpvN/S9z9G5KWSVqbvVzF5ExqGu9OqTPNeFdodvrzVpUR9qOS+iY8/oqkj0vooy53/zi7HZW0Td03FfWx8zPoZrejJffz/7ppGu9604yrC7ZdmdOflxH2PZLmm9lXzWy6pJWSdpTQx0XMbEZ24ERmNkPSt9V9U1HvkLQ6u79a0vYSe/mCbpnGO2+acZW87Uqf/tzdO/4jabnGj8j/t6R/LaOHnL7+TtIfs5/3y+5N0ssaf1n3vxp/RbRG0t9K2iXpo+x2Vhf19h+S9kt6T+PBmltSbzdr/K3he5L2ZT/Ly952ib46st24XBYIgivogCAIOxAEYQeCIOxAEIQdCIKwA0EQdiCI/wM4LDT8Dm7dlQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# weights & bias for nn layers\n",
    "W = tf.Variable(tf.random_normal([784, 10]))\n",
    "b = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "# parameters\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "num_epochs = 50\n",
    "num_iterations = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "        logits=hypothesis, labels=tf.stop_gradient(Y)\n",
    "    )\n",
    ")\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, axis=1), tf.argmax(Y, axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# train my model\n",
    "with tf.Session() as sess:\n",
    "    # initialize\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        avg_cost = 0\n",
    "\n",
    "        for iteration in range(num_iterations):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            _, cost_val = sess.run([train, cost], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "            avg_cost += cost_val / num_iterations\n",
    "\n",
    "        print(f\"Epoch: {(epoch + 1):04d}, Cost: {avg_cost:.9f}\")\n",
    "\n",
    "    print(\"Learning Finished!\")\n",
    "\n",
    "    # Test model and check accuracy\n",
    "    print(\n",
    "        \"Accuracy:\",\n",
    "        sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels}),\n",
    "    )\n",
    "\n",
    "    # Get one and predict\n",
    "    r = random.randint(0, mnist.test.num_examples - 1)\n",
    "\n",
    "    print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r : r + 1], axis=1)))\n",
    "    print(\n",
    "        \"Prediction: \",\n",
    "        sess.run(\n",
    "            tf.argmax(hypothesis, axis=1), feed_dict={X: mnist.test.images[r : r + 1]}\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    plt.imshow(\n",
    "        mnist.test.images[r : r + 1].reshape(28, 28),\n",
    "        cmap=\"Greys\",\n",
    "        interpolation=\"nearest\",\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
