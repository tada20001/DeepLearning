{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence data\n",
    "\n",
    "* 한 단어만으로는 전체 맥락을 이해하지 못한다.\n",
    "* 앞의 단어와 현재의 단어를 기반으로 이해해야 한다.(the previous word + this word, time series)\n",
    "* NN/CNN은 이러한 sequence data를 구현하기 어렵다.\n",
    "\n",
    "* 즉, 현재의 상태가 다음 상태에 영향을 줄 수 있는 네트워크 모델이 필요하다.\n",
    "\n",
    "### Recurrent Neural Network\n",
    "* 현재의 상태를 계산하고, 다시 그것을 입력으로 넣는 형태의 모델\n",
    "* 각 RNN에서 Y_hat(예측값)을 뽑아낼 수 있다. 계산방법은 다음과 같다.\n",
    "\n",
    "$$h(현재상태)= f_w(h_(이전상태), x) $$\n",
    "\n",
    "* fw는 weight를 갖는 함수로 모든 RNN에서 동일한 함수를 사용한다.\n",
    "\n",
    "* 입력이 두개이므로 weight도 두개가 필요하다. 예를 들어(Vanilla RNN)\n",
    "\n",
    "$$ h(현재상태) = tanh(W_1 h(이전상태) + W_2 X)$$\n",
    "\n",
    "$$ y(현재 상태) = W_3 h(현재상태)$$\n",
    "\n",
    "* h 는 일반적으로 hidden layer라고 하고, h(이전상태)는 초기에는 없기 때문에 일반적으로 0으로 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN의 여러가지 형태\n",
    "* one to one : Varinilla RNN\n",
    "* one to many : Image Captioning\n",
    "* many to one : sentiment classification. sequence of words -> sentiment\n",
    "* many to many : 기계 번역. seq of words -> seq of words\n",
    "* many to many : 프레임 차원의 동영상 분류 -> 설명 출력\n",
    "\n",
    "$$$$\n",
    "* Multi-layer RNN 도 가능하며, 마찬가지로 layer가 깊어지면 학습이 어려워진다. 이를 개선한 모델이 LSTM(Long Short Term Memory)이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN in TensorFlow"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# cell = tf.contrib.rnn.BasicRNNCell(num_units=hidden_size)  # activation 부분 (원하는 cell로 바꿀 수 있도록 별도로 설정 가능)\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(num_units=hidden_size)\n",
    "...\n",
    "outputs, _states = tf.nn.dynamic_rnn(cell, x_data, dtype=tf.float32) # 출력 부분  y로 가는 output 값과 state 값을 도출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "tf.set_random_seed(777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One node: 4 (input-dim) in 2 (hidden_size)\n",
    "\n",
    "* hidden_size를 어떻게 설정할 지에 따라 output의 dimension이 달라진다. 여기에서는 2로 설정한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* input shape = (1, 1, 4)  [[1, 0, 0, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "array([[[0.04945214, 0.04316235]]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 이 사례에서는 training이 없음\n",
    "hidden_size = 2\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(num_units=hidden_size)\n",
    "#cell = tf.keras.layers.LSTMCell(units=hidden_size)\n",
    "\n",
    "x_data = np.array([[[1, 0, 0, 0]]], dtype=np.float32) # 'h'\n",
    "#quesiton = tf.keras.layers.Input(shape=(1, 1, 4), dtype=tf.float32)\n",
    "\n",
    "outputs, _states = tf.nn.dynamic_rnn(cell, x_data, dtype=tf.float32)\n",
    "#outputs = tf.keras.layers.RNN(cell, dtype=tf.float32)(x_data)\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "import pprint as pp\n",
    "pp.pprint(outputs.eval(session=sess))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hidden_size를 2로 설정하였기 때문에 outputs 값도 두개가 나왔다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sequence input data의 경우  : hidden_size = 2, sequence_length = 5 (hello)\n",
    "\n",
    "* 이 경우, input data의 shape은 (1, 5, 4). 이것을 각 문자별로 펼쳐놓는다 (unfolding to n sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  hidden_size = 2\n",
    "  \n",
    "  sequence_length = 5 ( 입력 단어 수 )\n",
    "\n",
    " 이렇게 되면 출력 shape = (1, 5, 2) 가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5, 4)\n",
      "array([[[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(777)\n",
    "# one hot encoding\n",
    "h = [1, 0, 0, 0]\n",
    "e = [0, 1, 0, 0]\n",
    "l = [0, 0, 1, 0]\n",
    "o = [0, 0, 0, 1]\n",
    "\n",
    "hidden_size = 2\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(num_units=hidden_size)\n",
    "x_data = np.array([[h, e, l, l, o]], dtype=np.float32)  # sequence data\n",
    "print(x_data.shape)\n",
    "pp.pprint(x_data)\n",
    "\n",
    "outputs, _states = tf.nn.dynamic_rnn(cell, x_data, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[[ 0.04945214,  0.04316235],\n",
      "        [-0.00104636,  0.06992362],\n",
      "        [ 0.06311742, -0.06535073],\n",
      "        [ 0.11887082, -0.16511463],\n",
      "        [ 0.16751593, -0.26476774]]], dtype=float32)\n",
      "Tensor(\"rnn/transpose_1:0\", shape=(1, 5, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# outputs\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "pp.pprint(outputs.eval(session=sess))\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batching input\n",
    "\n",
    "* sequence를 하나씩 주는 것이 아니라 여러개를 줄 경우, 이를 batch_size로 표현 가능하다.\n",
    "\n",
    "* 예를 들어 hello, eolll, lleel shape = (3, 5, 4) 이면 batch_size = 3이 된다.\n",
    "* 이 경우 outputs의 shape = (3, 5, 2) 가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]],\n",
      "\n",
      "       [[0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.]],\n",
      "\n",
      "       [[0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.]]], dtype=float32)\n",
      "array([[[-0.04283834, -0.05121393],\n",
      "        [-0.03094209,  0.10285935],\n",
      "        [ 0.11129723, -0.03200451],\n",
      "        [ 0.22397222, -0.12367146],\n",
      "        [ 0.21238048, -0.0769559 ]],\n",
      "\n",
      "       [[ 0.01226371,  0.13834858],\n",
      "        [ 0.08454693,  0.03562944],\n",
      "        [ 0.21645911, -0.06988609],\n",
      "        [ 0.29929954, -0.14282013],\n",
      "        [ 0.35645092, -0.18373272]],\n",
      "\n",
      "       [[ 0.13940895, -0.10760844],\n",
      "        [ 0.24243172, -0.16845688],\n",
      "        [ 0.16465393,  0.04037705],\n",
      "        [ 0.16442199,  0.17125313],\n",
      "        [ 0.30980796,  0.02960309]]], dtype=float32)\n",
      "Tensor(\"rnn/transpose_1:0\", shape=(3, 5, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "hidden_size = 2\n",
    "sequece_length = 5\n",
    "batch_size = 3\n",
    "x_data = np.array([[h, e, l, l, o], \n",
    "                   [e, o, l, l, l], \n",
    "                   [l, l, e, e, l]], dtype=np.float32)\n",
    "\n",
    "pp.pprint(x_data)\n",
    "\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(num_units=hidden_size, state_is_tuple=True)\n",
    "outputs, _states = tf.nn.dynamic_rnn(cell, x_data, dtype=tf.float32)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "pp.pprint(outputs.eval(session=sess))\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
